{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "import loadBar\n",
    "from csv_parser import CSVParser\n",
    "from globals import RESOURCE_FOLDER, STEPSIZES, OUTPUT_WINDOW, INPUT_WINDOW, OUTPUT_FORECAST, DELETEABLE_COLUMNS, ONE_HOT_COLUMNS\n",
    "from markovSquares import apply_markov\n",
    "from feature_engineer import FeatureEngineer\n",
    "from exploring_data_functions import *\n",
    "\n",
    "from searoutePointFinder import fill_with_proximity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CSVParser(RESOURCE_FOLDER)\n",
    "index_data = parser.retrieve_training_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_data.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampler(df, sorting_column, freq):\n",
    "    unique_ids = df[sorting_column].unique()\n",
    "    final_df = pd.DataFrame()\n",
    "    partial_list = []\n",
    "\n",
    "    for i in range(len(unique_ids)):\n",
    "        loadBar.load_bar(len(unique_ids),i+1)\n",
    "        resample_partial = df[df[sorting_column] == unique_ids[i]].resample(freq).last()\n",
    "\n",
    "        resample_partial = fill_with_proximity(resample_partial)\n",
    "        partial_list.append(resample_partial)\n",
    "\n",
    "    for chunk in partial_list:\n",
    "        final_df = pd.concat([final_df,chunk])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "print(index_data)\n",
    "resampled_data_20min = resampler(index_data, \"vesselId\", \"20min\")\n",
    "\n",
    "resampled_data_20min.to_csv(\"../../Project materials(1)/data_resampled_20min.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv(\"../../Project materials(1)/data_resampled_20min.csv\")\n",
    "\n",
    "\n",
    "# total_df = pd.read_csv(RESOURCE_FOLDER+\"/resampled_data_h.csv\")\n",
    "\n",
    "total_df['etaParsed'] = pd.to_datetime(total_df['etaParsed'])\n",
    "total_df[\"time\"] = pd.to_datetime(total_df['time'])\n",
    "\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "\n",
    "total_df[\"etaParsed\"] = (total_df['etaParsed'] - start_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_diffs = total_df[\"time\"].diff()\n",
    "time_interval = time_diffs.dropna().iloc[0]\n",
    "time_interval = int(time_interval.total_seconds()/(60*20))\n",
    "\n",
    "\n",
    "\n",
    "total_df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df.to_csv(RESOURCE_FOLDER+\"/data_resampled_20min_markov.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         2024-01-01 00:00:00\n",
      "1         2024-01-01 00:20:00\n",
      "2         2024-01-01 00:40:00\n",
      "3         2024-01-01 01:00:00\n",
      "4         2024-01-01 01:20:00\n",
      "                  ...        \n",
      "5899716   2024-05-04 04:00:00\n",
      "5899717   2024-05-04 04:20:00\n",
      "5899718   2024-05-04 04:40:00\n",
      "5899719   2024-05-04 05:00:00\n",
      "5899720   2024-05-04 05:20:00\n",
      "Name: time, Length: 5899721, dtype: datetime64[ns]\n",
      "0         2024-01-01 00:00:00\n",
      "1         2024-01-01 00:20:00\n",
      "2         2024-01-01 00:40:00\n",
      "3         2024-01-01 01:00:00\n",
      "4         2024-01-01 01:20:00\n",
      "                  ...        \n",
      "5899716   2024-05-04 04:00:00\n",
      "5899717   2024-05-04 04:20:00\n",
      "5899718   2024-05-04 04:40:00\n",
      "5899719   2024-05-04 05:00:00\n",
      "5899720   2024-05-04 05:20:00\n",
      "Name: time, Length: 5899721, dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "total_df = pd.read_csv(RESOURCE_FOLDER+\"/data_resampled_20min.csv\")\n",
    "total_df[\"time\"] = pd.to_datetime(total_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot subtract DatetimeArray from ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m feature_engineering_functions \u001b[38;5;241m=\u001b[39m [categorize_navstat,categorize_rot,numerize_UN_LOCODE, numerize_ISO, days_to_etaParsed] \u001b[38;5;66;03m#,apply_markov\u001b[39;00m\n\u001b[0;32m      4\u001b[0m feature_engineer \u001b[38;5;241m=\u001b[39m FeatureEngineer(total_df)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mfeature_engineer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeature_engineering_functions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m total_df \u001b[38;5;241m=\u001b[39m feature_engineer\u001b[38;5;241m.\u001b[39mget_dataframe()\n\u001b[0;32m      8\u001b[0m total_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive - NTNU\\Studier\\2024_Host\\TDT4173 Moderne maskinlæring i praksis\\OceanWarlock\\OceanWarlock\\src\\feature_engineer.py:31\u001b[0m, in \u001b[0;36mFeatureEngineer.apply_features\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;124;03mApply a list of functions to the dataframe to add new features.\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03mParameters:\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03mfeatures (list): A list of functions that take a dataframe and return a series.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_feature\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive - NTNU\\Studier\\2024_Host\\TDT4173 Moderne maskinlæring i praksis\\OceanWarlock\\OceanWarlock\\src\\feature_engineer.py:18\u001b[0m, in \u001b[0;36mFeatureEngineer.add_feature\u001b[1;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_feature\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Apply a function to the dataframe to add a new feature.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    **kwargs: Additional keyword arguments to pass to the function.\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m     new_feature \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf[new_feature\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m new_feature\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\OneDrive - NTNU\\Studier\\2024_Host\\TDT4173 Moderne maskinlæring i praksis\\OceanWarlock\\OceanWarlock\\src\\exploring_data_functions.py:60\u001b[0m, in \u001b[0;36mdays_to_etaParsed\u001b[1;34m(total_df)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdays_to_etaParsed\u001b[39m(total_df):\n\u001b[1;32m---> 60\u001b[0m     return_values \u001b[38;5;241m=\u001b[39m (\u001b[43mtotal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43metaParsed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtotal_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mdays\n\u001b[0;32m     61\u001b[0m     return_values\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdays_to_etaParsed\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m return_values\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:6135\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6133\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6134\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:273\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;66;03m# NB: We assume that extract_array and ensure_wrapped_if_datetimelike\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;66;03m#  have already been called on `left` and `right`,\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;66;03m#  and `maybe_prepare_scalar_for_op` has already been called on `right`\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# We need to special-case datetime64/timedelta64 dtypes (e.g. because numpy\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# casts integer dtypes to timedelta64 when operating with timedelta64 - GH#22390)\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    267\u001b[0m     should_extension_dispatch(left, right)\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(right, (Timedelta, BaseOffset, Timestamp))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \u001b[38;5;66;03m# Timedelta/Timestamp and other custom scalars are included in the check\u001b[39;00m\n\u001b[0;32m    272\u001b[0m     \u001b[38;5;66;03m# because numexpr will fail on it, see GH#31457\u001b[39;00m\n\u001b[1;32m--> 273\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    275\u001b[0m     \u001b[38;5;66;03m# TODO we should handle EAs consistently and move this check before the if/else\u001b[39;00m\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;66;03m# (https://github.com/pandas-dev/pandas/issues/41165)\u001b[39;00m\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;66;03m# error: Argument 2 to \"_bool_arith_check\" has incompatible type\u001b[39;00m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:2200\u001b[0m, in \u001b[0;36mTimelikeOps.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2193\u001b[0m     ufunc \u001b[38;5;129;01min\u001b[39;00m [np\u001b[38;5;241m.\u001b[39misnan, np\u001b[38;5;241m.\u001b[39misinf, np\u001b[38;5;241m.\u001b[39misfinite]\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   2196\u001b[0m ):\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# numpy 1.18 changed isinf and isnan to not raise on dt64/td64\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(ufunc, method)(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ndarray, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m-> 2200\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__array_ufunc__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\base.py:2282\u001b[0m, in \u001b[0;36mExtensionArray.__array_ufunc__\u001b[1;34m(self, ufunc, method, *inputs, **kwargs)\u001b[0m\n\u001b[0;32m   2277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m   2278\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(other, (ABCSeries, ABCIndex, ABCDataFrame)) \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m   2279\u001b[0m ):\n\u001b[0;32m   2280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m-> 2282\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43marraylike\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_dispatch_ufunc_to_dunder_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mufunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m   2284\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m:\n\u001b[0;32m   2286\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mops_dispatch.pyx:113\u001b[0m, in \u001b[0;36mpandas._libs.ops_dispatch.maybe_dispatch_ufunc_to_dunder_op\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\arrays\\datetimelike.py:1499\u001b[0m, in \u001b[0;36mDatetimeLikeArrayMixin.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m other \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m other_is_dt64:\n\u001b[0;32m   1497\u001b[0m     \u001b[38;5;66;03m# GH#19959 datetime - datetime is well-defined as timedelta,\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m     \u001b[38;5;66;03m# but any other type - datetime is not well-defined.\u001b[39;00m\n\u001b[1;32m-> 1499\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot subtract \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(other)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1501\u001b[0m     )\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, PeriodDtype) \u001b[38;5;129;01mand\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mis_np_dtype(other_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;66;03m# TODO: Can we simplify/generalize these cases at all?\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot subtract \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mother\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot subtract DatetimeArray from ndarray"
     ]
    }
   ],
   "source": [
    "feature_engineering_functions = [categorize_navstat,categorize_rot,numerize_UN_LOCODE, numerize_ISO, days_to_etaParsed] #,apply_markov\n",
    "\n",
    "\n",
    "feature_engineer = FeatureEngineer(total_df)\n",
    "feature_engineer.apply_features(feature_engineering_functions)\n",
    "total_df = feature_engineer.get_dataframe()\n",
    "\n",
    "total_df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "one_hot_columns = ONE_HOT_COLUMNS\n",
    "total_df = pd.get_dummies(total_df, columns=one_hot_columns, drop_first=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make time series into supervised problem\n",
    "\n",
    "# 1 = 20 minutes\n",
    "# 3 = 1 hour\n",
    "# 18 = 6 hours\n",
    "# 72 = 24 hours\n",
    "# 144 = 2 days\n",
    "# 216 = 3 days\n",
    "# 288 = 4 days\n",
    "# 360 = 5 days\n",
    "\n",
    "\n",
    "\n",
    "def make_supervised(df, forecast_columns, sorting_column, input_window=1, output_window=1):\n",
    "    \"\"\"\n",
    "    Converts a multivariate time series dataframe into a supervised learning problem.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The original dataframe with time series data.\n",
    "    forecast_columns (list): A list of column names to forecast.\n",
    "    input_window (int): The number of past observations to use as features.\n",
    "    output_window (int): The number of steps to forecast into the future.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A new dataframe with supervised learning format.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    df_new = pd.DataFrame()\n",
    "    #Put in a for loop here where you iterate over all IDs, to make sure things get correct\n",
    "    unique_sorts = df[sorting_column].unique()\n",
    "\n",
    "    other_cols = [col for col in df.columns if col not in forecast_columns]\n",
    "    \n",
    "    #Iterate through all IDs\n",
    "    print(\"Creating supervised data\")\n",
    "    for i, sorts in enumerate(unique_sorts):\n",
    "        loadBar.load_bar(len(unique_sorts),i+1)\n",
    "        df_supervised = pd.DataFrame()\n",
    "        sort_df = df[df[sorting_column] == sorts]\n",
    "\n",
    "        #Iterate through all columns for input features\n",
    "        for col in forecast_columns: \n",
    "            for i in range(input_window, 0, -1):\n",
    "                df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
    "            \n",
    "            df_supervised[f\"{col}_t\"] = sort_df[col]\n",
    "            \n",
    "\n",
    "        # Create columns for forecast (target) with forward shift\n",
    "        for col in forecast_columns:\n",
    "            for j in range(output_window, 0,-1):\n",
    "                df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
    "\n",
    "        df_supervised = df_supervised.dropna()\n",
    "\n",
    "        df_supervised[other_cols] = sort_df[other_cols]\n",
    "        \n",
    "        df_new = pd.concat([df_new, df_supervised])\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "# total_df = pd.read_csv(\"../../build_resources/data_resampled_20min_markov.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating supervised data\n",
      "[====================] 100.0% complete\n"
     ]
    }
   ],
   "source": [
    "total_df = make_supervised(total_df, OUTPUT_FORECAST, \"vesselId\", input_window=INPUT_WINDOW, output_window=OUTPUT_WINDOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = total_df.drop(DELETEABLE_COLUMNS, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5896285\n",
      "                     latitude_t-4  longitude_t-4  cog_t-4  sog_t-4  rot_t-4  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00     -34.74370      -57.85130    284.0      0.7      0.0   \n",
      "2024-01-01 01:20:00      44.40593        8.88505     11.5      0.0      0.0   \n",
      "2024-01-01 01:20:00      52.32413        2.10535    320.0      1.2      0.0   \n",
      "2024-01-01 01:20:00      33.63707     -118.23330    162.8      9.9      0.0   \n",
      "2024-01-01 01:20:00      53.57537        8.56014    271.5      0.0      0.0   \n",
      "...                           ...            ...      ...      ...      ...   \n",
      "2024-05-07 23:20:00      43.58091       10.30400    352.5      0.0      0.0   \n",
      "2024-05-07 23:20:00       1.17829      103.75309    224.6      0.2      0.0   \n",
      "2024-05-07 23:20:00      59.57721       21.54090    296.3     14.7      3.0   \n",
      "2024-05-07 23:20:00      10.63965      106.76226    113.6      0.0      0.0   \n",
      "2024-05-07 23:20:00      36.86324     -122.49700    342.0      7.8      0.0   \n",
      "\n",
      "                     heading_t-4  latitude_t-3  longitude_t-3  cog_t-3  \\\n",
      "time                                                                     \n",
      "2024-01-01 01:20:00         88.0    -34.627229     -57.966135    284.0   \n",
      "2024-01-01 01:20:00        352.0     44.405910       8.885030     11.5   \n",
      "2024-01-01 01:20:00        134.0     52.325250       2.109120     75.0   \n",
      "2024-01-01 01:20:00        164.0     33.582630    -118.211500    161.6   \n",
      "2024-01-01 01:20:00        242.0     53.575370       8.560140    292.3   \n",
      "...                          ...           ...            ...      ...   \n",
      "2024-05-07 23:20:00        174.0     43.580910      10.304040    352.5   \n",
      "2024-05-07 23:20:00        282.0      1.178420     103.753180    238.6   \n",
      "2024-05-07 23:20:00        298.0     59.633370      21.432370    324.1   \n",
      "2024-05-07 23:20:00        113.0     10.639630     106.762260    113.6   \n",
      "2024-05-07 23:20:00        336.0     36.908650    -122.515590    339.0   \n",
      "\n",
      "                     sog_t-3  ...  portLongitude  portLatitude  \\\n",
      "time                          ...                                \n",
      "2024-01-01 01:20:00      0.7  ...     -71.618889    -33.587500   \n",
      "2024-01-01 01:20:00      0.0  ...       8.916389     44.404722   \n",
      "2024-01-01 01:20:00      0.8  ...       1.150000     51.800000   \n",
      "2024-01-01 01:20:00     10.0  ...    -117.917000     33.617000   \n",
      "2024-01-01 01:20:00      0.0  ...       8.554722     53.563611   \n",
      "...                      ...  ...            ...           ...   \n",
      "2024-05-07 23:20:00      0.0  ...      10.303056     43.555833   \n",
      "2024-05-07 23:20:00      0.1  ...     103.725278      1.292778   \n",
      "2024-05-07 23:20:00     13.5  ...      22.216389     60.437778   \n",
      "2024-05-07 23:20:00      0.0  ...     106.720833     10.759444   \n",
      "2024-05-07 23:20:00      7.7  ...    -122.210556     37.511389   \n",
      "\n",
      "                     navstat_cat_Anchor  navstat_cat_Moored  \\\n",
      "time                                                          \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "...                                 ...                 ...   \n",
      "2024-05-07 23:20:00               False                True   \n",
      "2024-05-07 23:20:00                True               False   \n",
      "2024-05-07 23:20:00               False               False   \n",
      "2024-05-07 23:20:00               False                True   \n",
      "2024-05-07 23:20:00               False               False   \n",
      "\n",
      "                     navstat_cat_OMW_E  navstat_cat_Other  rot_cat_Port_T_S  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "...                                ...                ...               ...   \n",
      "2024-05-07 23:20:00              False              False             False   \n",
      "2024-05-07 23:20:00              False              False             False   \n",
      "2024-05-07 23:20:00               True              False             False   \n",
      "2024-05-07 23:20:00              False              False             False   \n",
      "2024-05-07 23:20:00               True              False             False   \n",
      "\n",
      "                     rot_cat_Port_T_L  rot_cat_Star_T_L  rot_cat_Star_T_S  \n",
      "time                                                                       \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00              True             False             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "...                               ...               ...               ...  \n",
      "2024-05-07 23:20:00             False              True             False  \n",
      "2024-05-07 23:20:00             False              True             False  \n",
      "2024-05-07 23:20:00             False              True             False  \n",
      "2024-05-07 23:20:00             False              True             False  \n",
      "2024-05-07 23:20:00             False              True             False  \n",
      "\n",
      "[5896285 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Sorting columns\n",
    "def sort_columns(df):\n",
    "    selected_columns = df.filter(regex=r'_t$|_t\\+|_t-')\n",
    "    non_selected_columns = df.drop(selected_columns.columns, axis=1)\n",
    "    # Extract suffixes and assign _t as _t0\n",
    "    columns_with_suffix = []\n",
    "    for col in selected_columns.columns:\n",
    "        match = re.search(r\"_t([+-]?\\d*)$\", col)\n",
    "        # If there's no number after _t, treat it as _t0\n",
    "        suffix = int(match.group(1)) if match.group(1) else 0\n",
    "        columns_with_suffix.append((col, suffix))\n",
    "    \n",
    "    # Sort by suffix value (ascending)\n",
    "    sorted_t_columns = [col for col, _ in sorted(columns_with_suffix, key=lambda x: x[1])]\n",
    "    \n",
    "    # Reorder dataframe columns\n",
    "    return df[sorted_t_columns+non_selected_columns.columns.tolist()]\n",
    "\n",
    "total_df = total_df.dropna()\n",
    "print(len(total_df))\n",
    "total_df = total_df.sort_index(ascending = True)\n",
    "total_df=sort_columns(total_df)\n",
    "\n",
    "print(total_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     latitude_t-4  longitude_t-4  cog_t-4  sog_t-4  rot_t-4  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00     -34.74370      -57.85130    284.0      0.7      0.0   \n",
      "2024-01-01 01:20:00      44.40593        8.88505     11.5      0.0      0.0   \n",
      "2024-01-01 01:20:00      52.32413        2.10535    320.0      1.2      0.0   \n",
      "2024-01-01 01:20:00      33.63707     -118.23330    162.8      9.9      0.0   \n",
      "2024-01-01 01:20:00      53.57537        8.56014    271.5      0.0      0.0   \n",
      "\n",
      "                     heading_t-4  latitude_t-3  longitude_t-3  cog_t-3  \\\n",
      "time                                                                     \n",
      "2024-01-01 01:20:00         88.0    -34.627229     -57.966135    284.0   \n",
      "2024-01-01 01:20:00        352.0     44.405910       8.885030     11.5   \n",
      "2024-01-01 01:20:00        134.0     52.325250       2.109120     75.0   \n",
      "2024-01-01 01:20:00        164.0     33.582630    -118.211500    161.6   \n",
      "2024-01-01 01:20:00        242.0     53.575370       8.560140    292.3   \n",
      "\n",
      "                     sog_t-3  ...  portLongitude  portLatitude  \\\n",
      "time                          ...                                \n",
      "2024-01-01 01:20:00      0.7  ...     -71.618889    -33.587500   \n",
      "2024-01-01 01:20:00      0.0  ...       8.916389     44.404722   \n",
      "2024-01-01 01:20:00      0.8  ...       1.150000     51.800000   \n",
      "2024-01-01 01:20:00     10.0  ...    -117.917000     33.617000   \n",
      "2024-01-01 01:20:00      0.0  ...       8.554722     53.563611   \n",
      "\n",
      "                     navstat_cat_Anchor  navstat_cat_Moored  \\\n",
      "time                                                          \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "\n",
      "                     navstat_cat_OMW_E  navstat_cat_Other  rot_cat_Port_T_S  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "\n",
      "                     rot_cat_Port_T_L  rot_cat_Star_T_L  rot_cat_Star_T_S  \n",
      "time                                                                       \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00              True             False             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "\n",
      "[5 rows x 50 columns]\n"
     ]
    }
   ],
   "source": [
    "print(total_df.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_test_split(df, perc1, perc2, output_window):\n",
    "    y_list = []\n",
    "    for j in range(output_window):\n",
    "        for col in OUTPUT_FORECAST:\n",
    "            y_list.append(f\"{col}_t+{j+1}\")\n",
    "    ys = df[y_list]\n",
    "    Xs = df.drop(columns = y_list)\n",
    "\n",
    "    X_train = Xs.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    y_train = ys.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    X_val = Xs.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    y_val = ys.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    X_test = Xs.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "    y_test = ys.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(total_df, 0.75, 0.85, OUTPUT_WINDOW)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(stepsize, preds, y_val):\n",
    "    print(\"/\"+\"-\"*50+\"\\\\\")\n",
    "    print(\"Evaluating model with stepsize\", stepsize)\n",
    "\n",
    "    results = {\n",
    "        \"MAE\": mean_absolute_error(y_val, preds),\n",
    "        \"MSE\": np.square(np.subtract(y_val,preds)).mean(),\n",
    "        \"R2 Score\": r2_score(y_val, preds),\n",
    "        \"RMSE\": np.sqrt(np.square(np.subtract(y_val,preds)).mean())\n",
    "    }\n",
    "\n",
    "    for metric, value in results.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "    print(\"\\\\\"+\"-\"*50+\"/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    }
   ],
   "source": [
    "# #Tuning params\n",
    "# # We need to use XGB\n",
    "\n",
    "# # Define model with a high num_boost_round\n",
    "# model = xgb.XGBRFRegressor(\n",
    "#     objective=\"reg:squarederror\",\n",
    "#     tree_method=\"hist\",  # or \"hist\" if not using GPU\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Define parameter grid\n",
    "# param_grid = {\n",
    "#     \"max_depth\": [3, 5, 7],\n",
    "#     \"learning_rate\": [1],\n",
    "#     \"subsample\": [0.6, 0.8, 1.0],\n",
    "#     \"colsample_bynode\": [0.4, 0.6, 0.8],\n",
    "#     \"num_parallel_tree\": [50, 100, 200]\n",
    "# }\n",
    "\n",
    "# # Use TimeSeriesSplit for time series cross-validation\n",
    "# tscv = TimeSeriesSplit(n_splits=10)\n",
    "\n",
    "# # Set early stopping and validation set in fit parameters\n",
    "# fit_params = {\n",
    "#     \"eval_set\": [(X_val, y_val)],  # Validation set to monitor performance\n",
    "#     \"verbose\": 1\n",
    "# }\n",
    "\n",
    "# # RandomizedSearchCV with early stopping\n",
    "# random_search = RandomizedSearchCV(\n",
    "#     estimator=model,\n",
    "#     param_distributions=param_grid,\n",
    "#     n_iter=20,  # Number of sampled parameter combinations\n",
    "#     scoring=\"neg_mean_squared_error\",\n",
    "#     cv=tscv,\n",
    "#     verbose=1,\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # Fit with early stopping\n",
    "# random_search.fit(X_train, y_train, **fit_params)\n",
    "\n",
    "# # Output best parameters and number of boosting rounds\n",
    "# best_params = random_search.best_params_\n",
    "# best_num_boost_round = model.get_booster().best_iteration  # Retrieve best boosting rounds\n",
    "# print(\"Best parameters:\", best_params)\n",
    "# print(\"Best num_boost_round:\", best_num_boost_round)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     latitude_t-4  longitude_t-4  cog_t-4  sog_t-4  rot_t-4  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00    -34.743700     -57.851300    284.0      0.7      0.0   \n",
      "2024-01-01 01:20:00     44.405930       8.885050     11.5      0.0      0.0   \n",
      "2024-01-01 01:20:00     52.324130       2.105350    320.0      1.2      0.0   \n",
      "2024-01-01 01:20:00     33.637070    -118.233300    162.8      9.9      0.0   \n",
      "2024-01-01 01:20:00     53.575370       8.560140    271.5      0.0      0.0   \n",
      "...                           ...            ...      ...      ...      ...   \n",
      "2024-04-04 10:20:00     37.981977       8.333008    276.0     16.6      0.0   \n",
      "2024-04-04 10:20:00    -33.567415      16.853843    322.1     15.6      0.0   \n",
      "2024-04-04 10:20:00     40.276139     -10.943409    217.7     14.4      0.0   \n",
      "2024-04-04 10:20:00    -26.249571       4.188977    204.6     18.3      0.0   \n",
      "2024-04-04 10:20:00    -23.957620     -46.300340    346.9      0.0      0.0   \n",
      "\n",
      "                     heading_t-4  latitude_t-3  longitude_t-3  cog_t-3  \\\n",
      "time                                                                     \n",
      "2024-01-01 01:20:00         88.0    -34.627229     -57.966135    284.0   \n",
      "2024-01-01 01:20:00        352.0     44.405910       8.885030     11.5   \n",
      "2024-01-01 01:20:00        134.0     52.325250       2.109120     75.0   \n",
      "2024-01-01 01:20:00        164.0     33.582630    -118.211500    161.6   \n",
      "2024-01-01 01:20:00        242.0     53.575370       8.560140    292.3   \n",
      "...                          ...           ...            ...      ...   \n",
      "2024-04-04 10:20:00        276.0     38.005152       8.204773    276.0   \n",
      "2024-04-04 10:20:00        326.0    -33.495743      16.796501    322.1   \n",
      "2024-04-04 10:20:00        216.0     40.137730     -10.879855    217.7   \n",
      "2024-04-04 10:20:00        205.0    -26.249623       4.408333    204.6   \n",
      "2024-04-04 10:20:00        317.0    -23.957620     -46.300340    346.9   \n",
      "\n",
      "                     sog_t-3  ...  portLongitude  portLatitude  \\\n",
      "time                          ...                                \n",
      "2024-01-01 01:20:00      0.7  ...     -71.618889    -33.587500   \n",
      "2024-01-01 01:20:00      0.0  ...       8.916389     44.404722   \n",
      "2024-01-01 01:20:00      0.8  ...       1.150000     51.800000   \n",
      "2024-01-01 01:20:00     10.0  ...    -117.917000     33.617000   \n",
      "2024-01-01 01:20:00      0.0  ...       8.554722     53.563611   \n",
      "...                      ...  ...            ...           ...   \n",
      "2024-04-04 10:20:00     16.6  ...       9.000000     39.050000   \n",
      "2024-04-04 10:20:00     15.6  ...      18.436389    -33.909167   \n",
      "2024-04-04 10:20:00     14.4  ...      -0.212500     39.642778   \n",
      "2024-04-04 10:20:00     18.3  ...    -117.161389     32.684444   \n",
      "2024-04-04 10:20:00      0.0  ...     -46.300833    -23.968889   \n",
      "\n",
      "                     navstat_cat_Anchor  navstat_cat_Moored  \\\n",
      "time                                                          \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False               False   \n",
      "2024-01-01 01:20:00               False                True   \n",
      "...                                 ...                 ...   \n",
      "2024-04-04 10:20:00               False               False   \n",
      "2024-04-04 10:20:00               False               False   \n",
      "2024-04-04 10:20:00               False               False   \n",
      "2024-04-04 10:20:00               False               False   \n",
      "2024-04-04 10:20:00               False                True   \n",
      "\n",
      "                     navstat_cat_OMW_E  navstat_cat_Other  rot_cat_Port_T_S  \\\n",
      "time                                                                          \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00               True              False             False   \n",
      "2024-01-01 01:20:00              False              False             False   \n",
      "...                                ...                ...               ...   \n",
      "2024-04-04 10:20:00               True              False             False   \n",
      "2024-04-04 10:20:00               True              False             False   \n",
      "2024-04-04 10:20:00               True              False             False   \n",
      "2024-04-04 10:20:00               True              False             False   \n",
      "2024-04-04 10:20:00              False              False             False   \n",
      "\n",
      "                     rot_cat_Port_T_L  rot_cat_Star_T_L  rot_cat_Star_T_S  \n",
      "time                                                                       \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00              True             False             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "2024-01-01 01:20:00             False              True             False  \n",
      "...                               ...               ...               ...  \n",
      "2024-04-04 10:20:00             False              True             False  \n",
      "2024-04-04 10:20:00             False              True             False  \n",
      "2024-04-04 10:20:00             False              True             False  \n",
      "2024-04-04 10:20:00             False              True             False  \n",
      "2024-04-04 10:20:00             False              True             False  \n",
      "\n",
      "[4422214 rows x 44 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:etaParsed: object, UN_LOCODE: object, ISO: object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train)\n\u001b[1;32m----> 5\u001b[0m dtrain \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDMatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_val, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[0;32m      7\u001b[0m dtest_X \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\core.py:878\u001b[0m, in \u001b[0;36mDMatrix.__init__\u001b[1;34m(self, data, label, weight, base_margin, missing, silent, feature_names, feature_types, nthread, group, qid, label_lower_bound, label_upper_bound, feature_weights, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m handle, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43mdispatch_data_backend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmissing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnthread\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    888\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle \u001b[38;5;241m=\u001b[39m handle\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:1223\u001b[0m, in \u001b[0;36mdispatch_data_backend\u001b[1;34m(data, missing, threads, feature_names, feature_types, enable_categorical, data_split_mode)\u001b[0m\n\u001b[0;32m   1221\u001b[0m     data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m   1222\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_pandas_df(data):\n\u001b[1;32m-> 1223\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_from_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_split_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1231\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_cudf_df(data) \u001b[38;5;129;01mor\u001b[39;00m _is_cudf_ser(data):\n\u001b[0;32m   1233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _from_cudf_df(\n\u001b[0;32m   1234\u001b[0m         data, missing, threads, feature_names, feature_types, enable_categorical\n\u001b[0;32m   1235\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:640\u001b[0m, in \u001b[0;36m_from_pandas_df\u001b[1;34m(data, enable_categorical, missing, nthread, feature_names, feature_types, data_split_mode)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_pandas_df\u001b[39m(\n\u001b[0;32m    632\u001b[0m     data: DataFrame,\n\u001b[0;32m    633\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    638\u001b[0m     data_split_mode: DataSplitMode \u001b[38;5;241m=\u001b[39m DataSplitMode\u001b[38;5;241m.\u001b[39mROW,\n\u001b[0;32m    639\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DispatchedDataBackendReturnType:\n\u001b[1;32m--> 640\u001b[0m     df, feature_names, feature_types \u001b[38;5;241m=\u001b[39m \u001b[43m_transform_pandas_df\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_types\u001b[49m\n\u001b[0;32m    642\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m     handle \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_void_p()\n\u001b[0;32m    645\u001b[0m     _check_call(\n\u001b[0;32m    646\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGDMatrixCreateFromColumnar(\n\u001b[0;32m    647\u001b[0m             df\u001b[38;5;241m.\u001b[39marray_interface(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    652\u001b[0m         )\n\u001b[0;32m    653\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:603\u001b[0m, in \u001b[0;36m_transform_pandas_df\u001b[1;34m(data, enable_categorical, feature_names, feature_types, meta)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_pandas_df\u001b[39m(\n\u001b[0;32m    597\u001b[0m     data: DataFrame,\n\u001b[0;32m    598\u001b[0m     enable_categorical: \u001b[38;5;28mbool\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    601\u001b[0m     meta: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    602\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[PandasTransformed, Optional[FeatureNames], Optional[FeatureTypes]]:\n\u001b[1;32m--> 603\u001b[0m     \u001b[43mpandas_check_dtypes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_categorical\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m _matrix_meta:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmeta\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot have multiple columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:569\u001b[0m, in \u001b[0;36mpandas_check_dtypes\u001b[1;34m(data, enable_categorical)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dtype \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mdtypes:\n\u001b[0;32m    563\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\n\u001b[0;32m    564\u001b[0m         (dtype\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01min\u001b[39;00m _pandas_dtype_mapper)\n\u001b[0;32m    565\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pd_sparse_dtype(dtype)\n\u001b[0;32m    566\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (is_pd_cat_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m enable_categorical)\n\u001b[0;32m    567\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m is_pa_ext_dtype(dtype)\n\u001b[0;32m    568\u001b[0m     ):\n\u001b[1;32m--> 569\u001b[0m         \u001b[43m_invalid_dataframe_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_pd_sparse_dtype(dtype):\n\u001b[0;32m    572\u001b[0m         sparse_extension \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\xgboost\\data.py:356\u001b[0m, in \u001b[0;36m_invalid_dataframe_dtype\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    354\u001b[0m type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.dtypes for data must be int, float, bool or category.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    355\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_err\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_ENABLE_CAT_ERR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m--> 356\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: DataFrame.dtypes for data must be int, float, bool or category. When categorical type is supplied, the experimental DMatrix parameter`enable_categorical` must be set to `True`.  Invalid columns:etaParsed: object, UN_LOCODE: object, ISO: object"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_train)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest_X = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\"objective\": \"reg:squarederror\",\n",
    "            \"max_depth\": 5,\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"tree-method\": \"gpu_hist\",\n",
    "            \"col_sample_bynode\": 0.5,\n",
    "            \"num_parallel_tree\": 100,\n",
    "            \"subsample\": 0.8,\n",
    "            \"learning_rate\": 1,\n",
    "            #\"n_estimators\": 100,\n",
    "            #\"reg_alpha\": 0.1,\n",
    "            #\"reg_lambda\": 0.1,\n",
    "            #\"n_jobs\": -1,\n",
    "            \"verbosity\": 1\n",
    "            }\n",
    "\n",
    "num_boost_round = 5\n",
    "\n",
    "early_stopping_rounds = 2\n",
    "\n",
    "print(dtrain)\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round, evals=[(dval, \"validation\")], early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "\n",
    "preds = model.predict(dtest_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_n_min_mark(timestamp, n=1):\n",
    "    timestamp = pd.to_datetime(timestamp)\n",
    "    minutes = timestamp.minute\n",
    "    closest_mark = round(minutes / (n*20)) * n*20\n",
    "    if closest_mark == 60:\n",
    "        rounded_timestamp = timestamp.replace(minute=0, second=0, microsecond=0) + pd.Timedelta(hours=1)\n",
    "    else:\n",
    "        rounded_timestamp = timestamp.replace(minute=closest_mark, second=0, microsecond=0)\n",
    "    \n",
    "    return rounded_timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift_to_back(process_df):      \n",
    "    for _, col in enumerate(OUTPUT_FORECAST):\n",
    "\n",
    "        max_suffix_neg = 0\n",
    "        max_suffix_pos = 0\n",
    "        \n",
    "        # Identify existing suffixes in the process_df for the current column\n",
    "        while f\"{col}_t-{max_suffix_neg+1}\" in process_df.columns:\n",
    "            max_suffix_neg += 1\n",
    "        while f\"{col}_t+{max_suffix_pos+1}\" in process_df.columns:\n",
    "            max_suffix_pos += 1\n",
    "        for shift in range(max_suffix_neg - 1, -max_suffix_pos, -1):  # Start from max_suffix-1 down to 0\n",
    "            if shift == 0:\n",
    "                # Set the new predicted value as the most recent\n",
    "                process_df[f\"{col}_t\"] = process_df[f\"{col}_t+1\"]\n",
    "            elif shift == 1:\n",
    "                # Shift the column\n",
    "                process_df[f\"{col}_t-{shift}\"] = process_df[f\"{col}_t\"]\n",
    "            elif shift > 1:\n",
    "                # Shift the column\n",
    "                process_df[f\"{col}_t-{shift}\"] = process_df[f\"{col}_t-{shift - 1}\"]\n",
    "            else:\n",
    "                process_df[f\"{col}_t+{-shift}\"] = process_df[f\"{col}_t+{-shift + 1}\"]\n",
    "\n",
    "        for shift in range(1, max_suffix_pos+1):\n",
    "            process_df = process_df.drop(columns=[f\"{col}_t+{shift}\"])\n",
    "    \n",
    "    return process_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_far_future(model, features, test_df,  forecast_columns):\n",
    "    \n",
    "    X_test = features.copy().iloc[-1:]\n",
    "    preds = pd.DataFrame(columns=[\"vesselId\", \"approximate_time\"])\n",
    "    \n",
    "    # Determine the furthest time in 20-minute intervals\n",
    "    furthest_time = closest_n_min_mark(test_df[\"time\"].max())\n",
    "    current_time = closest_n_min_mark(X_test.index.max())\n",
    "    \n",
    "    # Generate the future time steps at 20-minute intervals\n",
    "    future_steps = pd.date_range(start=current_time, end=furthest_time, freq='20min')\n",
    "    \n",
    "    for future_time in future_steps:\n",
    "        y_pred = model.predict(xgb.DMatrix(X_test))\n",
    "\n",
    "        new_row = pd.DataFrame({\n",
    "            \"vesselId\": [test_df[\"vesselId\"].iloc[0]],\n",
    "            \"approximate_time\": [future_time]\n",
    "        })\n",
    "        for idx, col in enumerate(forecast_columns):\n",
    "            new_row[f\"{col}\"] = y_pred[0, idx]  # Use the predicted value\n",
    "        selected_columns = X_test.filter(regex=r'_t$|_t\\+|_t-')\n",
    "        non_selected_columns = X_test.drop(selected_columns.columns, axis=1)\n",
    "        new_row[non_selected_columns.columns] = X_test[non_selected_columns.columns].iloc[0]\n",
    "        \n",
    "        \n",
    "        preds = pd.concat([preds, new_row], ignore_index=True)\n",
    "        \n",
    "        # Update X_test for the next iteration\n",
    "        for idx, col in enumerate(forecast_columns):\n",
    "\n",
    "            max_suffix = 0\n",
    "            \n",
    "            # Identify existing suffixes in the X_test for the current column\n",
    "            while f\"{col}_t-{max_suffix+1}\" in X_test.columns:\n",
    "                max_suffix += 1\n",
    "            for shift in range(max_suffix - 1, -1, -1):  # Start from max_suffix-1 down to 0\n",
    "                if shift == 0:\n",
    "                    # Set the new predicted value as the most recent\n",
    "                    X_test[f\"{col}_t\"] = y_pred[0, idx]\n",
    "                elif shift == 1:\n",
    "                    # Shift the column\n",
    "                    X_test[f\"{col}_t-{shift}\"] = X_test[f\"{col}_t\"]\n",
    "                else:\n",
    "                    # Shift the column\n",
    "                    X_test[f\"{col}_t-{shift}\"] = X_test[f\"{col}_t-{shift - 1}\"]\n",
    "    \n",
    "    return preds\n",
    "\n",
    "\n",
    "csv_parser = CSVParser(folderpath=\"../../Project materials(1)\")\n",
    "\n",
    "test_df = csv_parser.retrieve_test_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(latest_features, feature_engineering_functions):\n",
    "\n",
    "    feature_engineer = FeatureEngineer(latest_features)\n",
    "    feature_engineer.apply_features(feature_engineering_functions)\n",
    "    latest_features = feature_engineer.get_dataframe()\n",
    "    latest_features = pd.get_dummies(latest_features, columns=ONE_HOT_COLUMNS, drop_first=False)\n",
    "    \n",
    "    latest_features = make_supervised(latest_features, OUTPUT_FORECAST, \"vesselId\" , INPUT_WINDOW, OUTPUT_WINDOW)\n",
    "    latest_features = shift_to_back(latest_features)\n",
    "    latest_features = latest_features.dropna()\n",
    "    latest_features = latest_features.drop(DELETEABLE_COLUMNS, axis=1)\n",
    "    latest_features = sort_columns(latest_features)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return latest_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_times(model,total_df,test_df):\n",
    "    unique_sorts = test_df[\"vesselId\"].unique()\n",
    "    preds_df = pd.DataFrame()\n",
    "    result = pd.DataFrame()\n",
    "\n",
    "    for sorts in unique_sorts:\n",
    "        latest_features=total_df[total_df[\"vesselId\"] == sorts]\n",
    "        test_by_vessel_df = test_df[test_df[\"vesselId\"] == sorts]\n",
    "\n",
    "        latest_features = preprocess(latest_features, feature_engineering_functions)\n",
    "\n",
    "        preds = predict_far_future(model, latest_features, test_by_vessel_df, OUTPUT_FORECAST)\n",
    "        preds_df = pd.concat([preds_df, preds])\n",
    "    \n",
    "    for test in test_df.iterrows():\n",
    "        test=pd.Series(test[1])\n",
    "        new_row = pd.DataFrame()\n",
    "        new_row=preds_df[\n",
    "            (preds_df[\"vesselId\"] == test[\"vesselId\"]) & \n",
    "            (preds_df[\"approximate_time\"] == closest_n_min_mark(test[\"time\"]))\n",
    "            ][[\"latitude\", \"longitude\"]]\n",
    "        new_row[\"ID\"] = test[\"ID\"]\n",
    "        new_row[\"time\"] = test[\"time\"]\n",
    "        \n",
    "        result = pd.concat([result, new_row])\n",
    "    result[\"latitude_predicted\"] = result[\"latitude\"]\n",
    "    result[\"longitude_predicted\"] = result[\"longitude\"]\n",
    "\n",
    "    return result[[\"ID\",\"longitude_predicted\",\"latitude_predicted\"]]\n",
    "\n",
    "print(test_df)\n",
    "total_df = pd.read_csv(\"../../Project materials(1)/data_resampled_20min.csv\")\n",
    "total_df[\"time\"] = pd.to_datetime(total_df['time'])\n",
    "total_df.set_index(\"time\", inplace=True)\n",
    "print(total_df.head())\n",
    "result_df = predict_times(model, total_df, test_df)\n",
    "print(result_df)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn results into a csv file\n",
    "result_df.to_csv(\"../../Project materials(1)/results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_importance(model, height=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First model:\n",
    "Included navstat and etaParsed\n",
    "\n",
    "Timewindow: (3,2)\n",
    "\n",
    "MAE: 0.8521843262281953 \n",
    "\n",
    "MSE: longitude_t+1    21.225563\n",
    "\n",
    "latitude_t+1      1.993130\n",
    "\n",
    "longitude_t+2    38.471488\n",
    "\n",
    "latitude_t+2      3.840146\n",
    "\n",
    "dtype: float64\n",
    "\n",
    "R2 Score: 0.9958523607729776\n",
    "\n",
    "RMSE: longitude_t+1    4.607121\n",
    "\n",
    "latitude_t+1     1.411783\n",
    "\n",
    "longitude_t+2    6.202539\n",
    "\n",
    "latitude_t+2     1.959629\n",
    "\n",
    "dtype: float64\n",
    "\n",
    "\n",
    "### Second model:\n",
    "\n",
    "Added cog, rot and heading to target features.\n",
    "\n",
    "Timewindow: (3,2)\n",
    "\n",
    "MAE: 7.198335594601071\n",
    "MSE: latitude_t+1        1.980426\n",
    "longitude_t+1      21.577318\n",
    "cog_t+1          1820.208937\n",
    "rot_t+1            92.532501\n",
    "heading_t+1      1172.604934\n",
    "latitude_t+2        3.813640\n",
    "longitude_t+2      39.218475\n",
    "cog_t+2          2370.325440\n",
    "rot_t+2           107.991661\n",
    "heading_t+2      1769.347459\n",
    "dtype: float64\n",
    "R2 Score: 0.8826565909012996\n",
    "RMSE: latitude_t+1      1.407276\n",
    "longitude_t+1     4.645139\n",
    "cog_t+1          42.663907\n",
    "rot_t+1           9.619382\n",
    "heading_t+1      34.243320\n",
    "latitude_t+2      1.952854\n",
    "longitude_t+2     6.262466\n",
    "cog_t+2          48.685988\n",
    "rot_t+2          10.391904\n",
    "heading_t+2      42.063612\n",
    "dtype: float64\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
