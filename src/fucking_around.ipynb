{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import os\n",
    "from feature_engineering.tensor_features import develop_features, floating_conv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_handler import LocalToLargeDataLoader\n",
    "from path_finder import path_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training data...\n"
     ]
    }
   ],
   "source": [
    "data_loader = LocalToLargeDataLoader(print_progress=True)\n",
    "parsed_data = data_loader.load_raw_data(path=\"../../resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_data = parsed_data.copy()\n",
    "index_data.set_index(\"time\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[--------------------] 1.01% complete\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 58\u001b[0m\n\u001b[0;32m     54\u001b[0m         final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final_df,chunk])\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m final_df\n\u001b[1;32m---> 58\u001b[0m resampled_data_h \u001b[38;5;241m=\u001b[39m \u001b[43mresampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvesselId\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mh\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m resampled_data_20min \u001b[38;5;241m=\u001b[39m resampler(index_data, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvesselId\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m20min\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     61\u001b[0m resampled_data_h\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresampled_data_h.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[7], line 50\u001b[0m, in \u001b[0;36mresampler\u001b[1;34m(df, sorting_column, freq)\u001b[0m\n\u001b[0;32m     48\u001b[0m     loadBar\u001b[38;5;241m.\u001b[39mload_bar(\u001b[38;5;28mlen\u001b[39m(unique_ids),i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     49\u001b[0m     resample_partial \u001b[38;5;241m=\u001b[39m df[df[sorting_column] \u001b[38;5;241m==\u001b[39m unique_ids[i]]\u001b[38;5;241m.\u001b[39mresample(freq)\u001b[38;5;241m.\u001b[39mlast()\n\u001b[1;32m---> 50\u001b[0m     resample_partial \u001b[38;5;241m=\u001b[39m \u001b[43mfill_with_proximity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresample_partial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     partial_list\u001b[38;5;241m.\u001b[39mappend(resample_partial)\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m partial_list:\n",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m, in \u001b[0;36mfill_with_proximity\u001b[1;34m(df)\u001b[0m\n\u001b[0;32m     20\u001b[0m current_time \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex[i]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Get the last known value index (timestamp)\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m last_known_index \u001b[38;5;241m=\u001b[39m \u001b[43mdf_ffill\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_valid_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m last_known_index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     distance_to_ffill \u001b[38;5;241m=\u001b[39m (current_time \u001b[38;5;241m-\u001b[39m last_known_index)\u001b[38;5;241m.\u001b[39mtotal_seconds()  \u001b[38;5;66;03m# distance to last known\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:12866\u001b[0m, in \u001b[0;36mNDFrame.first_valid_index\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  12792\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  12793\u001b[0m \u001b[38;5;129m@doc\u001b[39m(position\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst\u001b[39m\u001b[38;5;124m\"\u001b[39m, klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m  12794\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst_valid_index\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  12795\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12796\u001b[0m \u001b[38;5;124;03m    Return index for {position} non-NA value or None, if no non-NA value is found.\u001b[39;00m\n\u001b[0;32m  12797\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12864\u001b[0m \u001b[38;5;124;03m    If DataFrame is empty, returns None.\u001b[39;00m\n\u001b[0;32m  12865\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_valid_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfirst\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:12786\u001b[0m, in \u001b[0;36mNDFrame._find_valid_index\u001b[1;34m(self, how)\u001b[0m\n\u001b[0;32m  12772\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  12773\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_find_valid_index\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, how: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Hashable \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m  12774\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  12775\u001b[0m \u001b[38;5;124;03m    Retrieves the index of the first valid value.\u001b[39;00m\n\u001b[0;32m  12776\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  12784\u001b[0m \u001b[38;5;124;03m    idx_first_valid : type of index\u001b[39;00m\n\u001b[0;32m  12785\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 12786\u001b[0m     is_valid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnotna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m  12787\u001b[0m     idxpos \u001b[38;5;241m=\u001b[39m find_valid_index(how\u001b[38;5;241m=\u001b[39mhow, is_valid\u001b[38;5;241m=\u001b[39mis_valid)\n\u001b[0;32m  12788\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m idxpos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:6503\u001b[0m, in \u001b[0;36mDataFrame.notna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6501\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39mnotna, klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   6502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnotna\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 6503\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m~\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:6490\u001b[0m, in \u001b[0;36mDataFrame.isna\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   6488\u001b[0m \u001b[38;5;129m@doc\u001b[39m(NDFrame\u001b[38;5;241m.\u001b[39misna, klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m   6489\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m-> 6490\u001b[0m     res_mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43misna\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6491\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res_mgr, axes\u001b[38;5;241m=\u001b[39mres_mgr\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m   6492\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124misna\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\base.py:178\u001b[0m, in \u001b[0;36mDataManager.isna\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mapply\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[1;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[0;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:393\u001b[0m, in \u001b[0;36mBlock.apply\u001b[1;34m(self, func, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    389\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    apply the function to my values; return a block if we are not\u001b[39;00m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;124;03m    one\u001b[39;00m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 393\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    395\u001b[0m     result \u001b[38;5;241m=\u001b[39m maybe_coerce_values(result)\n\u001b[0;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_split_op_result(result)\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[0m, in \u001b[0;36misna\u001b[1;34m(obj)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mbool_] \u001b[38;5;241m|\u001b[39m NDFrame:\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;124;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[0m, in \u001b[0;36m_isna\u001b[1;34m(obj, inf_as_na)\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np\u001b[38;5;241m.\u001b[39mndarray, ABCExtensionArray)):\n\u001b[1;32m--> 207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_can_hold_na:\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[0m, in \u001b[0;36m_isna_array\u001b[1;34m(values, inf_as_na)\u001b[0m\n\u001b[0;32m    298\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m~\u001b[39mnp\u001b[38;5;241m.\u001b[39misfinite(values)\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 300\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import loadBar\n",
    "\n",
    "\n",
    "def fill_with_proximity(df):\n",
    "    # Forward fill first\n",
    "    df_ffill = df.ffill()\n",
    "    \n",
    "    # Backward fill next\n",
    "    df_bfill = df.bfill()\n",
    "    # Create a mask for original missing values\n",
    "    mask = df.isna()\n",
    "\n",
    "    # Create a new DataFrame to hold the results\n",
    "    filled_df = df.copy()\n",
    "\n",
    "    # Iterate over each missing value\n",
    "    for i in range(len(df)):\n",
    "        if mask.iloc[i, 0]:  # Check if the value is missing\n",
    "            # Get the current index (timestamp)\n",
    "            current_time = df.index[i]\n",
    "\n",
    "            # Get the last known value index (timestamp)\n",
    "            last_known_index = df_ffill.first_valid_index()\n",
    "            if last_known_index is not None:\n",
    "                distance_to_ffill = (current_time - last_known_index).total_seconds()  # distance to last known\n",
    "\n",
    "            # Get the next known value index (timestamp)\n",
    "            next_known_index = df_bfill.first_valid_index()\n",
    "            if next_known_index is not None:\n",
    "                distance_to_bfill = (next_known_index - current_time).total_seconds()  # distance to next known\n",
    "\n",
    "            # Fill based on proximity\n",
    "            if (last_known_index is not None and distance_to_ffill < distance_to_bfill) or next_known_index is None:\n",
    "                filled_df.iloc[i] = df_ffill.iloc[i]\n",
    "            else:\n",
    "                filled_df.iloc[i] = df_bfill.iloc[i]\n",
    "\n",
    "    return filled_df\n",
    "\n",
    "\n",
    "\n",
    "def resampler(df, sorting_column, freq):\n",
    "    unique_ids = df[sorting_column].unique()\n",
    "    final_df = pd.DataFrame()\n",
    "    partial_list = []\n",
    "\n",
    "    for i in range(len(unique_ids)):\n",
    "        loadBar.load_bar(len(unique_ids),i+1)\n",
    "        resample_partial = df[df[sorting_column] == unique_ids[i]].resample(freq).last()\n",
    "        resample_partial = fill_with_proximity(resample_partial)\n",
    "        partial_list.append(resample_partial)\n",
    "\n",
    "    for chunk in partial_list:\n",
    "        final_df = pd.concat([final_df,chunk])\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "resampled_data_h = resampler(index_data, \"vesselId\", \"h\")\n",
    "resampled_data_20min = resampler(index_data, \"vesselId\", \"20min\")\n",
    "\n",
    "resampled_data_h.to_csv('resampled_data_h.csv')\n",
    "resampled_data_20min.to_csv('resampled_data_20min.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We have two resampled and therefore regular datasets, now we need to make our time series into a supervised problem.\n",
    "#First I need to change navstat into a categorical feature:\n",
    "\n",
    "\n",
    "# Define categories based on ranges or discrete values\n",
    "pretty_20m = pd.read_csv(\"../../resources/resampled_data_20min.csv\")\n",
    "\n",
    "pretty_h = pd.read_csv(\"../../resources/resampled_data_h.csv\")\n",
    "\n",
    "navstat_unique = pretty_h[\"navstat\"].unique()\n",
    "\n",
    "pretty_20m[\"navstat\"] = pd.Categorical(pretty_20m[\"navstat\"], categories=navstat_unique, ordered=True)\n",
    "\n",
    "pretty_h[\"navstat\"] = pd.Categorical(pretty_h[\"navstat\"], categories=navstat_unique, ordered=True)\n",
    "\n",
    "\n",
    "# Let's make dummys \n",
    "\n",
    "pretty_h = pd.get_dummies(pretty_h, columns=[\"navstat\"], drop_first=True)\n",
    "pretty_20m = pd.get_dummies(pretty_20m, columns = [\"navstat\"], drop_first=True)\n",
    "\n",
    "pretty_20m.set_index(\"time\", inplace=True)\n",
    "pretty_h.set_index(\"time\", inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       cog   sog  rot  heading  latitude  longitude  \\\n",
      "time                                                                  \n",
      "2024-01-01 00:00:00  284.0   0.7  0.0     88.0 -34.74370   -57.8513   \n",
      "2024-01-01 01:00:00   88.2  14.3  0.0     86.0 -35.16805   -56.5319   \n",
      "2024-01-01 02:00:00   88.2  14.3  0.0     86.0 -35.16805   -56.5319   \n",
      "2024-01-01 03:00:00   88.2  14.3  0.0     86.0 -35.16805   -56.5319   \n",
      "2024-01-01 04:00:00   88.2  14.3  0.0     86.0 -35.16805   -56.5319   \n",
      "\n",
      "                                     vesselId                    portId  \\\n",
      "time                                                                      \n",
      "2024-01-01 00:00:00  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "2024-01-01 01:00:00  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "2024-01-01 02:00:00  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "2024-01-01 03:00:00  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "2024-01-01 04:00:00  61e9f3a8b937134a3c4bfdf7  61d371c43aeaecc07011a37f   \n",
      "\n",
      "                               etaParsed UN_LOCODE  ... navstat_3.0  \\\n",
      "time                                                ...               \n",
      "2024-01-01 00:00:00  2024-01-09 23:00:00     CLSAI  ...       False   \n",
      "2024-01-01 01:00:00  2024-01-09 23:00:00     CLSAI  ...       False   \n",
      "2024-01-01 02:00:00  2024-01-09 23:00:00     CLSAI  ...       False   \n",
      "2024-01-01 03:00:00  2024-01-09 23:00:00     CLSAI  ...       False   \n",
      "2024-01-01 04:00:00  2024-01-09 23:00:00     CLSAI  ...       False   \n",
      "\n",
      "                     navstat_15.0  navstat_4.0  navstat_14.0  navstat_11.0  \\\n",
      "time                                                                         \n",
      "2024-01-01 00:00:00         False        False         False         False   \n",
      "2024-01-01 01:00:00         False        False         False         False   \n",
      "2024-01-01 02:00:00         False        False         False         False   \n",
      "2024-01-01 03:00:00         False        False         False         False   \n",
      "2024-01-01 04:00:00         False        False         False         False   \n",
      "\n",
      "                     navstat_12.0  navstat_6.0  navstat_7.0  navstat_13.0  \\\n",
      "time                                                                        \n",
      "2024-01-01 00:00:00         False        False        False         False   \n",
      "2024-01-01 01:00:00         False        False        False         False   \n",
      "2024-01-01 02:00:00         False        False        False         False   \n",
      "2024-01-01 03:00:00         False        False        False         False   \n",
      "2024-01-01 04:00:00         False        False        False         False   \n",
      "\n",
      "                     navstat_9.0  \n",
      "time                              \n",
      "2024-01-01 00:00:00        False  \n",
      "2024-01-01 01:00:00        False  \n",
      "2024-01-01 02:00:00        False  \n",
      "2024-01-01 03:00:00        False  \n",
      "2024-01-01 04:00:00        False  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "(1966932, 27)\n"
     ]
    }
   ],
   "source": [
    "print(pretty_h.head())\n",
    "print(pretty_h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t\"] = sort_df[col]\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:28: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:29: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t\"] = sort_df[col]\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
      "C:\\Users\\Bruker\\AppData\\Local\\Temp\\ipykernel_10836\\1265698822.py:34: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['cog_t-3', 'cog_t-2', 'cog_t-1', 'cog_t', 'sog_t-3', 'sog_t-2',\n",
       "       'sog_t-1', 'sog_t', 'rot_t-3', 'rot_t-2',\n",
       "       ...\n",
       "       'navstat_13.0_t-1', 'navstat_13.0_t', 'navstat_9.0_t-3',\n",
       "       'navstat_9.0_t-2', 'navstat_9.0_t-1', 'navstat_9.0_t', 'latitude_t+2',\n",
       "       'latitude_t+1', 'longitude_t+2', 'longitude_t+1'],\n",
       "      dtype='object', length=112)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make time series into supervised problem\n",
    "def make_supervised(df, forecast_columns, sorting_column, input_window=1, output_window=1):\n",
    "    \"\"\"\n",
    "    Converts a multivariate time series dataframe into a supervised learning problem.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The original dataframe with time series data.\n",
    "    forecast_columns (list): A list of column names to forecast.\n",
    "    input_window (int): The number of past observations to use as features.\n",
    "    output_window (int): The number of steps to forecast into the future.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A new dataframe with supervised learning format.\n",
    "    \"\"\"\n",
    "    # Create a dataframe to hold the transformed features\n",
    "    df_supervised = pd.DataFrame()\n",
    "\n",
    "    #Put in a for loop here where you iterate over all IDs, to make sure things get correct\n",
    "    unique_sorts = df[sorting_column].unique()\n",
    "    \n",
    "    #Iterate through all IDs\n",
    "    for sorts in unique_sorts:\n",
    "        sort_df = df[df[sorting_column] == sorts]\n",
    "\n",
    "        #Iterate through all columns for input features\n",
    "        for col in sort_df.columns: \n",
    "            for i in range(input_window, 0, -1):\n",
    "                df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
    "            df_supervised[f\"{col}_t\"] = sort_df[col]\n",
    "\n",
    "    # Create columns for forecast (target) with forward shift\n",
    "        for col in forecast_columns:\n",
    "            for j in range(output_window, 0, -1):\n",
    "                df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
    "        \n",
    "\n",
    "    # Remove rows with NaN values caused by the shifting process\n",
    "    df_supervised.dropna(inplace=True)\n",
    "    \n",
    "    return df_supervised\n",
    "\n",
    "supervised_h = make_supervised(pretty_h, [\"latitude\", \"longitude\"],\"vesselId\" , 3, 2)\n",
    "\n",
    "supervised_h.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_columns(df):\n",
    "    \n",
    "    # Extract suffixes and assign _t as _t0\n",
    "    columns_with_suffix = []\n",
    "    for col in df.columns:\n",
    "        match = re.search(r\"_t([+-]?\\d*)$\", col)\n",
    "        # If there's no number after _t, treat it as _t0\n",
    "        suffix = int(match.group(1)) if match.group(1) else 0\n",
    "        columns_with_suffix.append((col, suffix))\n",
    "    \n",
    "    # Sort by suffix value (ascending)\n",
    "    sorted_t_columns = [col for col, _ in sorted(columns_with_suffix, key=lambda x: x[1])]\n",
    "    \n",
    "    # Reorder dataframe columns\n",
    "    return df[sorted_t_columns]\n",
    "\n",
    "supervised_t=sort_columns(supervised_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude_t+2\n",
      "longitude_t+2\n",
      "latitude_t+1\n",
      "longitude_t+1\n",
      "cog_t\n",
      "sog_t\n",
      "rot_t\n",
      "heading_t\n",
      "latitude_t\n",
      "longitude_t\n",
      "vesselId_t\n",
      "portId_t\n",
      "etaParsed_t\n",
      "UN_LOCODE_t\n",
      "ISO_t\n",
      "portLongitude_t\n",
      "portLatitude_t\n",
      "navstat_5.0_t\n",
      "navstat_1.0_t\n",
      "navstat_8.0_t\n",
      "navstat_2.0_t\n",
      "navstat_3.0_t\n",
      "navstat_15.0_t\n",
      "navstat_4.0_t\n",
      "navstat_14.0_t\n",
      "navstat_11.0_t\n",
      "navstat_12.0_t\n",
      "navstat_6.0_t\n",
      "navstat_7.0_t\n",
      "navstat_13.0_t\n",
      "navstat_9.0_t\n",
      "cog_t-1\n",
      "sog_t-1\n",
      "rot_t-1\n",
      "heading_t-1\n",
      "latitude_t-1\n",
      "longitude_t-1\n",
      "vesselId_t-1\n",
      "portId_t-1\n",
      "etaParsed_t-1\n",
      "UN_LOCODE_t-1\n",
      "ISO_t-1\n",
      "portLongitude_t-1\n",
      "portLatitude_t-1\n",
      "navstat_5.0_t-1\n",
      "navstat_1.0_t-1\n",
      "navstat_8.0_t-1\n",
      "navstat_2.0_t-1\n",
      "navstat_3.0_t-1\n",
      "navstat_15.0_t-1\n",
      "navstat_4.0_t-1\n",
      "navstat_14.0_t-1\n",
      "navstat_11.0_t-1\n",
      "navstat_12.0_t-1\n",
      "navstat_6.0_t-1\n",
      "navstat_7.0_t-1\n",
      "navstat_13.0_t-1\n",
      "navstat_9.0_t-1\n",
      "cog_t-2\n",
      "sog_t-2\n",
      "rot_t-2\n",
      "heading_t-2\n",
      "latitude_t-2\n",
      "longitude_t-2\n",
      "vesselId_t-2\n",
      "portId_t-2\n",
      "etaParsed_t-2\n",
      "UN_LOCODE_t-2\n",
      "ISO_t-2\n",
      "portLongitude_t-2\n",
      "portLatitude_t-2\n",
      "navstat_5.0_t-2\n",
      "navstat_1.0_t-2\n",
      "navstat_8.0_t-2\n",
      "navstat_2.0_t-2\n",
      "navstat_3.0_t-2\n",
      "navstat_15.0_t-2\n",
      "navstat_4.0_t-2\n",
      "navstat_14.0_t-2\n",
      "navstat_11.0_t-2\n",
      "navstat_12.0_t-2\n",
      "navstat_6.0_t-2\n",
      "navstat_7.0_t-2\n",
      "navstat_13.0_t-2\n",
      "navstat_9.0_t-2\n",
      "cog_t-3\n",
      "sog_t-3\n",
      "rot_t-3\n",
      "heading_t-3\n",
      "latitude_t-3\n",
      "longitude_t-3\n",
      "vesselId_t-3\n",
      "portId_t-3\n",
      "etaParsed_t-3\n",
      "UN_LOCODE_t-3\n",
      "ISO_t-3\n",
      "portLongitude_t-3\n",
      "portLatitude_t-3\n",
      "navstat_5.0_t-3\n",
      "navstat_1.0_t-3\n",
      "navstat_8.0_t-3\n",
      "navstat_2.0_t-3\n",
      "navstat_3.0_t-3\n",
      "navstat_15.0_t-3\n",
      "navstat_4.0_t-3\n",
      "navstat_14.0_t-3\n",
      "navstat_11.0_t-3\n",
      "navstat_12.0_t-3\n",
      "navstat_6.0_t-3\n",
      "navstat_7.0_t-3\n",
      "navstat_13.0_t-3\n",
      "navstat_9.0_t-3\n"
     ]
    }
   ],
   "source": [
    "for col in supervised_t.columns:\n",
    "    print(col)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
