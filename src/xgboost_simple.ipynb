{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "from collections import deque\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "simplefilter(action=\"ignore\", category=UserWarning)\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "import loadBar\n",
    "from csv_parser import CSVParser\n",
    "from globals import RESOURCE_FOLDER, STEPSIZES, OUTPUT_WINDOW, INPUT_WINDOW, OUTPUT_FORECAST, DELETEABLE_COLUMNS, ONE_HOT_COLUMNS\n",
    "from markovSquares import apply_markov\n",
    "from feature_engineer import FeatureEngineer\n",
    "from exploring_data_functions import *\n",
    "\n",
    "from searoutePointFinder import fill_with_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CSVParser(RESOURCE_FOLDER)\n",
    "total_df = parser.retrieve_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"time\"] = pd.to_datetime(total_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_indexes_within_timewindow(df, time_col, timewindow):\n",
    "    # Initialize the dictionary to store the mappings\n",
    "    index_map = {}    \n",
    "\n",
    "    within_window = deque()\n",
    "    \n",
    "    # Iterate over the DataFrame by index and row\n",
    "    for current_idx in range(len((df))):\n",
    "        current_row = df.iloc[current_idx]\n",
    "        current_time = current_row[time_col]\n",
    "        \n",
    "        # Remove outdated timestamps from the left of the deque\n",
    "        while within_window and (current_time - within_window[0][1] > timewindow):\n",
    "            index_map[within_window[0][0]] = within_window[-1][0]\n",
    "            within_window.popleft()\n",
    "        \n",
    "        # If this is the last row, map all the remaining indexes to this row\n",
    "        if current_idx == df.index[-1]:\n",
    "            for idx, _ in within_window:\n",
    "                index_map[idx] = current_idx\n",
    "        \n",
    "        # Add the current index and time to the deque\n",
    "        within_window.append((current_idx, current_time))\n",
    "    \n",
    "    return index_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diffs_within_window(df):\n",
    "    result_list= []\n",
    "    vessel_dfs = df.groupby('vesselId')\n",
    "    j=0\n",
    "    for _, vessel_df in vessel_dfs:\n",
    "        j+=1\n",
    "        loadBar.load_bar(len(vessel_dfs), j)\n",
    "        \n",
    "        vessel_df = vessel_df.sort_values(by='time')\n",
    "        groups = vessel_df.groupby(pd.Grouper(key=\"time\", freq='5D'))\n",
    "        for _, group in groups:\n",
    "                for i in range(len(group)):\n",
    "                    current_row = group.iloc[0]\n",
    "                    future_row = group.iloc[i]\n",
    "                    new_row = current_row.copy()\n",
    "                    new_row['next_latitude'] = future_row['latitude']\n",
    "                    new_row['next_longitude'] = future_row['longitude']\n",
    "                    new_row['time_diff'] = (future_row['time'] - current_row['time']).total_seconds()\n",
    "                    result_list.append(new_row)\n",
    "    \n",
    "    print(\"Concating\")\n",
    "    result_df = pd.DataFrame(result_list)\n",
    "    result_df['diff_seconds'] = result_df['time_diff']\n",
    "    result_df['diff_minutes'] = result_df['diff_seconds'] / 60\n",
    "    result_df['diff_hours'] = result_df['diff_seconds'] / 3600\n",
    "    result_df['diff_days'] = result_df['diff_seconds'] / 86400\n",
    "    \n",
    "    # Identify the last row for each vesselId for separation\n",
    "    last_rows = df.groupby('vesselId').tail(1)\n",
    "\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    result_df\n",
    "    \n",
    "    return result_df, last_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diffs_with_coords(df):\n",
    "    # Ensure the DataFrame is sorted by vesselId and time\n",
    "    df = df.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "    last_rows = df.groupby('vesselId').tail(1)\n",
    "    # Calculate the time difference in seconds between consecutive times per vesselId\n",
    "    df['time_diff'] = df.groupby('vesselId')['time'].diff().shift(-1)\n",
    "    \n",
    "    # Create columns for each time unit by converting from seconds\n",
    "    df['diff_seconds'] = df['time_diff'].dt.total_seconds()\n",
    "    df['diff_minutes'] = df['diff_seconds'] / 60\n",
    "    df['diff_hours'] = df['diff_seconds'] / 3600\n",
    "    df['diff_days'] = df['diff_seconds'] / 86400\n",
    "    \n",
    "    # Get the latitude and longitude of the next row within each vesselId group\n",
    "    df['next_latitude'] = df.groupby('vesselId')['latitude'].shift(-1)\n",
    "    df['next_longitude'] = df.groupby('vesselId')['longitude'].shift(-1)\n",
    "    \n",
    "    # Identify the last row for each vesselId\n",
    "    \n",
    "    \n",
    "    # Remove the last rows from the main DataFrame\n",
    "    df = df.drop(last_rows.index).reset_index(drop=True)\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    \n",
    "    # Drop the temporary 'time_diff' column\n",
    "    df = df.drop(columns=['time_diff'])\n",
    "    \n",
    "    return df, last_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[====================] 100.0% complete\n",
      "Concating\n"
     ]
    }
   ],
   "source": [
    "total_df, last_rows = calculate_time_diffs_within_window(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'cog', 'sog', 'rot', 'heading', 'navstat', 'latitude',\n",
      "       'longitude', 'vesselId', 'portId', 'etaParsed', 'UN_LOCODE', 'ISO',\n",
      "       'portLongitude', 'portLatitude', 'next_latitude', 'next_longitude',\n",
      "       'time_diff', 'diff_seconds', 'diff_minutes', 'diff_hours', 'diff_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(total_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_functions = [categorize_navstat, numerize_UN_LOCODE, numerize_ISO] #, apply_markov, minutes_to_etaParsed, categorize_rot, type_dummies\n",
    "\n",
    "\n",
    "feature_engineer = FeatureEngineer(total_df)\n",
    "feature_engineer.apply_features(feature_engineering_functions)\n",
    "total_df = feature_engineer.get_dataframe()\n",
    "\n",
    "total_df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_numeric_columns(df):\n",
    "    # Select columns that are either of type bool, float, or int\n",
    "    df = df.select_dtypes(include=['bool', 'float', 'int'])\n",
    "    return df\n",
    "\n",
    "total_df = remove_non_numeric_columns(total_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1520450\n"
     ]
    }
   ],
   "source": [
    "print(len(total_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df_old, perc1, perc2):\n",
    "\n",
    "    df = df_old.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    y_list = ['next_latitude', 'next_longitude'] #'next_latitude', 'next_longitude'\n",
    "    ys = df[y_list]\n",
    "    Xs = df.drop(columns = y_list)\n",
    "\n",
    "    X_train = Xs.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    y_train = ys.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    X_val = Xs.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    y_val = ys.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    X_test = Xs.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "    y_test = ys.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(total_df, 0.85, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols= X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cog   sog  rot  heading  navstat  latitude  longitude  \\\n",
      "0        310.1   0.0    0      312        5  47.26120 -122.38266   \n",
      "1        201.8  21.5    0      204        0  56.32365   16.85772   \n",
      "2        316.4   0.0    0      127        5  53.85903    8.73065   \n",
      "3         27.4  20.6    0       29        0  37.89129   15.44732   \n",
      "4        116.2  17.0   -4      115        0  48.27546 -124.09802   \n",
      "...        ...   ...  ...      ...      ...       ...        ...   \n",
      "1292377   37.9   0.0    0      243        5  53.57619    8.55677   \n",
      "1292378  106.4  13.4    0      105        0  48.45468 -126.65454   \n",
      "1292379  192.0  16.0    0      189        0  35.36056  129.41808   \n",
      "1292380   27.7  17.8    4       26        0  41.10578    2.08802   \n",
      "1292381   30.0  15.3    0       32        0 -29.96579   31.12882   \n",
      "\n",
      "         portLongitude  portLatitude  time_diff  diff_seconds  diff_minutes  \\\n",
      "0          -122.406667     47.267222   169352.0      169352.0   2822.533333   \n",
      "1            10.869167     53.952222   339841.0      339841.0   5664.016667   \n",
      "2             9.135833     53.895833   273496.0      273496.0   4558.266667   \n",
      "3            15.564444     38.200278   135209.0      135209.0   2253.483333   \n",
      "4          -122.406667     47.267222   308280.0      308280.0   5138.000000   \n",
      "...                ...           ...        ...           ...           ...   \n",
      "1292377       8.554722     53.563611   240008.0      240008.0   4000.133333   \n",
      "1292378    -123.432600     48.435960    73230.0       73230.0   1220.500000   \n",
      "1292379     129.386667     35.499722   192240.0      192240.0   3204.000000   \n",
      "1292380       2.164722     41.340278    19234.0       19234.0    320.566667   \n",
      "1292381      25.636389    -33.961389        0.0           0.0      0.000000   \n",
      "\n",
      "         diff_hours  diff_days  UN_LOCODE_num  ISO_num  \n",
      "0         47.042222   1.960093            237       16  \n",
      "1         94.400278   3.933345            541       25  \n",
      "2         75.971111   3.165463            185       25  \n",
      "3         37.558056   1.564919            575       38  \n",
      "4         85.633333   3.568056            237       16  \n",
      "...             ...        ...            ...      ...  \n",
      "1292377   66.668889   2.777870             61       25  \n",
      "1292378   20.341667   0.847569            109       41  \n",
      "1292379   53.400000   2.225000            112       13  \n",
      "1292380    5.342778   0.222616              5        4  \n",
      "1292381    0.000000   0.000000            224        1  \n",
      "\n",
      "[1292382 rows x 16 columns]\n",
      "<xgboost.core.DMatrix object at 0x70616a9be900>\n",
      "[0]\tvalidation-rmse:4.47753\n",
      "[1]\tvalidation-rmse:3.74496\n",
      "[2]\tvalidation-rmse:3.54641\n",
      "[3]\tvalidation-rmse:3.43395\n",
      "[4]\tvalidation-rmse:3.30428\n",
      "[5]\tvalidation-rmse:3.22279\n",
      "[6]\tvalidation-rmse:3.11750\n",
      "[7]\tvalidation-rmse:3.04377\n",
      "[8]\tvalidation-rmse:2.97275\n",
      "[9]\tvalidation-rmse:2.89430\n",
      "[10]\tvalidation-rmse:2.83339\n",
      "[11]\tvalidation-rmse:2.78284\n",
      "[12]\tvalidation-rmse:2.74010\n",
      "[13]\tvalidation-rmse:2.69102\n",
      "[14]\tvalidation-rmse:2.64819\n",
      "[15]\tvalidation-rmse:2.60562\n",
      "[16]\tvalidation-rmse:2.56225\n",
      "[17]\tvalidation-rmse:2.52302\n",
      "[18]\tvalidation-rmse:2.48073\n",
      "[19]\tvalidation-rmse:2.43854\n",
      "[20]\tvalidation-rmse:2.40533\n",
      "[21]\tvalidation-rmse:2.36907\n",
      "[22]\tvalidation-rmse:2.33499\n",
      "[23]\tvalidation-rmse:2.29885\n",
      "[24]\tvalidation-rmse:2.27119\n",
      "[25]\tvalidation-rmse:2.24039\n",
      "[26]\tvalidation-rmse:2.21051\n",
      "[27]\tvalidation-rmse:2.18438\n",
      "[28]\tvalidation-rmse:2.15526\n",
      "[29]\tvalidation-rmse:2.12903\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest_X = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\"objective\": \"reg:squarederror\",\n",
    "            \"max_depth\": 7,\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"tree-method\": \"gpu_hist\",\n",
    "            \"colsample_bynode\": 0.4,\n",
    "            \"num_parallel_tree\": 50,\n",
    "            \"subsample\": 0.6,\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": 1,\n",
    "            #\"n_estimators\": 100,\n",
    "            #\"reg_alpha\": 0.1,\n",
    "            #\"reg_lambda\": 0.1,\n",
    "            #\"n_jobs\": -1,\n",
    "            \"verbosity\": 1\n",
    "            }\n",
    "\n",
    "#Subsample was 0.8, num-parallel tree was 100, colsample-bynode was 0.5 and max-depth was 5. Before tuning. \n",
    "\n",
    "#After first round of tuning we got sumbsample was 0.6, num-parallel tree was 50, colsample-bynode was 0.4 and max-depth was 7. Before tuning. \n",
    "\n",
    "num_boost_round = 30\n",
    "\n",
    "#Tried 50, but that stagnated quickly. So reducing again to 30.  \n",
    "\n",
    "\n",
    "early_stopping_rounds = 3\n",
    "\n",
    "print(dtrain)\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round, evals=[(dval, \"validation\")], \n",
    "                  early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "\n",
    "preds = model.predict(dtest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diff_with_last_rows(test_df, last_rows):\n",
    "    # Merge test_df with last_rows on vesselId to get the last row time for each vesselId\n",
    "    merged_df = pd.merge(\n",
    "        test_df[[\"ID\", \"vesselId\", \"time\"]],\n",
    "        last_rows,\n",
    "        on='vesselId',\n",
    "        suffixes=('', '_last')\n",
    "    )\n",
    "    print(merged_df.columns)\n",
    "    # Calculate time difference between test_df time and last row time\n",
    "    merged_df['time_diff'] = (merged_df['time'] - merged_df['time_last']).dt.total_seconds()\n",
    "    \n",
    "    # Create columns for each time unit by converting from seconds\n",
    "    merged_df['diff_seconds'] = merged_df['time_diff']\n",
    "    merged_df['diff_minutes'] = merged_df['time_diff'] / 60\n",
    "    merged_df['diff_hours'] = merged_df['time_diff'] / 3600\n",
    "    merged_df['diff_days'] = merged_df['time_diff'] / 86400\n",
    "    \n",
    "    # Drop the temporary 'time_diff' column and 'time_last' if desired\n",
    "    merged_df = merged_df.drop(columns=[ 'time_last'])\n",
    "    \n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = parser.retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                  vesselId                time  scaling_factor\n",
      "0   0  61e9f3aeb937134a3c4bfe3d 2024-05-08 00:03:16             0.3\n",
      "1   1  61e9f473b937134a3c4c02df 2024-05-08 00:06:17             0.3\n",
      "2   2  61e9f469b937134a3c4c029b 2024-05-08 00:10:02             0.3\n",
      "3   3  61e9f45bb937134a3c4c0221 2024-05-08 00:10:34             0.3\n",
      "4   4  61e9f38eb937134a3c4bfd8d 2024-05-08 00:12:27             0.3\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   time    cog   sog  rot  heading  navstat  latitude  \\\n",
      "0   2024-02-06 01:08:32  315.5   6.4    0      313       11  34.89519   \n",
      "1   2024-02-14 03:52:58  119.9   0.0    2      332        5  40.72416   \n",
      "2   2024-03-20 17:13:04  273.8  15.5    0      275        0  30.52393   \n",
      "3   2024-03-20 18:19:26   38.8  15.6    0       42        0  25.59151   \n",
      "4   2024-03-23 16:29:44  111.6   0.0  128      511        5  37.95007   \n",
      "..                  ...    ...   ...  ...      ...      ...       ...   \n",
      "683 2024-05-07 23:59:07  359.1  13.4    0        1        0  52.19131   \n",
      "684 2024-05-07 23:59:08   12.3  17.1    0       13        0  38.96142   \n",
      "685 2024-05-07 23:59:08  269.8  14.9   -1      270        0  49.71372   \n",
      "686 2024-05-07 23:59:08    8.0  18.7    0        6        0  38.27895   \n",
      "687 2024-05-07 23:59:08  336.0  14.3    5      337        0  38.98635   \n",
      "\n",
      "     longitude                   vesselId                    portId  \\\n",
      "0     28.73453   61e9f3cbb937134a3c4bff09  61d3735d3aeaecc07011a5ae   \n",
      "1     29.48081   61e9f3c6b937134a3c4bfed5  61d38259b7b7526e1adf3a41   \n",
      "2   -127.04948   61e9f3d5b937134a3c4bff23  61d384fab7b7526e1adf3e12   \n",
      "3    120.97204   61e9f400b937134a3c4bfffb  634c4de270937fc01c3a7744   \n",
      "4     23.60080   61e9f43fb937134a3c4c016f  61d3763e93c6feb83e5eb468   \n",
      "..         ...                        ...                       ...   \n",
      "683   -5.82223  clh6aqawa0002gh0zypfa5dut  634c4de270937fc01c3a7417   \n",
      "684  -12.00502   61e9f3aeb937134a3c4bfe43  634c4de270937fc01c3a76a1   \n",
      "685   -5.22042   61e9f43db937134a3c4c0169  634c4de270937fc01c3a787b   \n",
      "686   10.78280   61e9f469b937134a3c4c029b  61d3781293c6feb83e5eb73b   \n",
      "687  -75.13275   62080cff66fc0a8e43c6123a  61d38528b7b7526e1adf3e6f   \n",
      "\n",
      "              etaParsed UN_LOCODE ISO  portLongitude  portLatitude  \n",
      "0   2024-12-06 17:30:00     EGPSD  EG      32.309444     31.253333  \n",
      "1   2024-12-25 15:00:00     TRDRC  TR      29.841944     40.751111  \n",
      "2   2024-04-05 15:00:00     USNTD  US    -119.207778     34.149167  \n",
      "3   2024-03-21 20:00:00     TWTPE  TW     121.517000     25.033000  \n",
      "4   2024-01-01 04:00:00     GRPIR  GR      23.610400     37.951140  \n",
      "..                  ...       ...  ..            ...           ...  \n",
      "683 2024-05-08 05:00:00     IEWCQ  IE      -7.100000     52.250000  \n",
      "684 2024-05-10 03:00:00     PTCAS  PT      -9.417000     38.700000  \n",
      "685 2024-05-15 23:00:00     GBPLV  GB      -5.317000     50.083000  \n",
      "686 2024-05-08 12:45:00     ITCVV  IT      11.780833     42.098889  \n",
      "687 2024-05-07 23:00:00     USILG  US     -75.521667     39.716667  \n",
      "\n",
      "[688 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "print(last_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'vesselId', 'time', 'time_last', 'cog', 'sog', 'rot', 'heading',\n",
      "       'navstat', 'latitude', 'longitude', 'portId', 'etaParsed', 'UN_LOCODE',\n",
      "       'ISO', 'portLongitude', 'portLatitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_df=calculate_time_diff_with_last_rows(test_df,last_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'vesselId', 'time', 'cog', 'sog', 'rot', 'heading', 'navstat',\n",
      "       'latitude', 'longitude', 'portId', 'etaParsed', 'UN_LOCODE', 'ISO',\n",
      "       'portLongitude', 'portLatitude', 'time_diff', 'diff_seconds',\n",
      "       'diff_minutes', 'diff_hours', 'diff_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineer = FeatureEngineer(test_df)\n",
    "feature_engineer.apply_features(feature_engineering_functions)\n",
    "test_df = feature_engineer.get_dataframe()\n",
    "\n",
    "test_df.set_index(\"time\", inplace=True)\n",
    "test_df = remove_non_numeric_columns(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID    cog   sog  rot  heading  navstat  latitude  \\\n",
      "time                                                                    \n",
      "2024-05-08 00:03:16   0  179.6   0.0    0      344        5  31.14647   \n",
      "2024-05-08 00:06:17   1   24.7   0.0    0      214        5  14.81694   \n",
      "2024-05-08 00:10:02   2    8.0  18.7    0        6        0  38.27895   \n",
      "2024-05-08 00:10:34   3  321.3   0.1    0       70        1 -43.53785   \n",
      "2024-05-08 00:12:27   4  291.0   0.3    0      275        2  48.53320   \n",
      "\n",
      "                     longitude  portLongitude  portLatitude  time_diff  \\\n",
      "time                                                                     \n",
      "2024-05-08 00:03:16  -81.49789     -81.496667     31.140556      900.0   \n",
      "2024-05-08 00:06:17  120.29625     120.279444     14.808333      541.0   \n",
      "2024-05-08 00:10:02   10.78280      11.780833     42.098889      654.0   \n",
      "2024-05-08 00:10:34  172.83522     172.716111    -43.606111     1080.0   \n",
      "2024-05-08 00:12:27   -6.12003      -4.474167     48.380556     1258.0   \n",
      "\n",
      "                     diff_seconds  diff_minutes  diff_hours  diff_days  \\\n",
      "time                                                                     \n",
      "2024-05-08 00:03:16         900.0     15.000000    0.250000   0.010417   \n",
      "2024-05-08 00:06:17         541.0      9.016667    0.150278   0.006262   \n",
      "2024-05-08 00:10:02         654.0     10.900000    0.181667   0.007569   \n",
      "2024-05-08 00:10:34        1080.0     18.000000    0.300000   0.012500   \n",
      "2024-05-08 00:12:27        1258.0     20.966667    0.349444   0.014560   \n",
      "\n",
      "                     UN_LOCODE_num  ISO_num  \n",
      "time                                         \n",
      "2024-05-08 00:03:16              0        0  \n",
      "2024-05-08 00:06:17              1        1  \n",
      "2024-05-08 00:10:02              2        2  \n",
      "2024-05-08 00:10:34              3        3  \n",
      "2024-05-08 00:12:27              4        4  \n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, input_df):\n",
    "    # Extract the features for prediction, excluding the 'ID' column\n",
    "    features_df = input_df.drop(columns=['ID'])\n",
    "    features_df = features_df[X_train_cols]\n",
    "    # Generate predictions using the model\n",
    "    predictions = model.predict(xgb.DMatrix(features_df))\n",
    "    \n",
    "    # Create a DataFrame with the predictions, renaming columns as required\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['next_latitude', 'next_longitude'])\n",
    "    predictions_df = predictions_df.rename(columns={'next_latitude': 'latitude', 'next_longitude': 'longitude'})\n",
    "    \n",
    "    # Combine the 'ID' column with the predictions DataFrame\n",
    "    result_df = pd.concat([input_df['ID'].reset_index(drop=True), predictions_df], axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = make_predictions(model, test_df)\n",
    "result_fin = pd.DataFrame()\n",
    "result_fin[[\"ID\",\"longitude_predicted\",\"latitude_predicted\"]]=result_df[[\"ID\",\"longitude\",\"latitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_fin.to_csv(RESOURCE_FOLDER+\"/result_simple.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
