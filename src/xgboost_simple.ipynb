{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "simplefilter(action=\"ignore\", category=UserWarning)\n",
    "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
    "\n",
    "import loadBar\n",
    "from csv_parser import CSVParser\n",
    "from globals import RESOURCE_FOLDER, STEPSIZES, OUTPUT_WINDOW, INPUT_WINDOW, OUTPUT_FORECAST, DELETEABLE_COLUMNS, ONE_HOT_COLUMNS\n",
    "from markovSquares import apply_markov\n",
    "from feature_engineer import FeatureEngineer\n",
    "from exploring_data_functions import *\n",
    "\n",
    "from searoutePointFinder import fill_with_proximity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = CSVParser(RESOURCE_FOLDER)\n",
    "total_df = parser.retrieve_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df[\"time\"] = pd.to_datetime(total_df['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diffs_within_window(df, timewindow=timedelta(days=5), n=2):\n",
    "    result_df= pd.DataFrame()\n",
    "    vessel_dfs = df.groupby('vesselId')\n",
    "    \n",
    "    for _, vessel_df in vessel_dfs:\n",
    "        vessel_df = vessel_df.sort_values(by='time')\n",
    "\n",
    "        for i in range(len(vessel_df)):\n",
    "            loadBar.load_bar(len(vessel_df),i)\n",
    "            current_row = vessel_df.iloc[i]\n",
    "            #Pick n random rows that are later in the dataframe but within the timewindow\n",
    "            future_rows = vessel_df.iloc[i+1:][(vessel_df['time'] > current_row['time']) \n",
    "                                               & (vessel_df['time'] <= current_row['time'] + timewindow)]\n",
    "            if len(future_rows) > n:\n",
    "                future_rows = future_rows.sample(n=n)\n",
    "            elif len(future_rows) == 0:\n",
    "                break\n",
    "            \n",
    "            #Add the current row, future latitudes, future longitudes and the time differences to the result_df as n new rows\n",
    "            for future_row in future_rows.iterrows():\n",
    "                new_row = current_row.copy()\n",
    "                new_row['next_latitude'] = future_row[1]['latitude']\n",
    "                new_row['next_longitude'] = future_row[1]['longitude']\n",
    "                new_row['time_diff'] = (future_row[1]['time'] - current_row['time']).total_seconds()\n",
    "                result_df = pd.concat([result_df,new_row])\n",
    "    \n",
    "    result_df['diff_seconds'] = result_df['time_diff'].dt.total_seconds()\n",
    "    result_df['diff_minutes'] = result_df['diff_seconds'] / 60\n",
    "    result_df['diff_hours'] = result_df['diff_seconds'] / 3600\n",
    "    result_df['diff_days'] = result_df['diff_seconds'] / 86400\n",
    "    \n",
    "    # Identify the last row for each vesselId for separation\n",
    "    last_rows = df.groupby('vesselId').tail(1)\n",
    "    \n",
    "    # Remove the last rows from the main DataFrame\n",
    "    result_df = result_df.drop(last_rows.index).reset_index(drop=True)\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    \n",
    "    return result_df, last_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diffs_with_coords(df):\n",
    "    # Ensure the DataFrame is sorted by vesselId and time\n",
    "    df = df.sort_values(by=['vesselId', 'time']).reset_index(drop=True)\n",
    "    last_rows = df.groupby('vesselId').tail(1)\n",
    "    \n",
    "    print(last_rows.head())\n",
    "    # Calculate the time difference in seconds between consecutive times per vesselId\n",
    "    df['time_diff'] = df.groupby('vesselId')['time'].diff().shift(-1)\n",
    "    \n",
    "    # Create columns for each time unit by converting from seconds\n",
    "    df['diff_seconds'] = df['time_diff'].dt.total_seconds()\n",
    "    df['diff_minutes'] = df['diff_seconds'] / 60\n",
    "    df['diff_hours'] = df['diff_seconds'] / 3600\n",
    "    df['diff_days'] = df['diff_seconds'] / 86400\n",
    "    \n",
    "    # Get the latitude and longitude of the next row within each vesselId group\n",
    "    df['next_latitude'] = df.groupby('vesselId')['latitude'].shift(-1)\n",
    "    df['next_longitude'] = df.groupby('vesselId')['longitude'].shift(-1)\n",
    "    \n",
    "    # Identify the last row for each vesselId\n",
    "    \n",
    "    \n",
    "    # Remove the last rows from the main DataFrame\n",
    "    df = df.drop(last_rows.index).reset_index(drop=True)\n",
    "    last_rows = last_rows.reset_index(drop=True)\n",
    "    \n",
    "    # Drop the temporary 'time_diff' column\n",
    "    df = df.drop(columns=['time_diff'])\n",
    "    \n",
    "    return df, last_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==------------------] 14.08% complete\r"
     ]
    }
   ],
   "source": [
    "total_df, last_rows = calculate_time_diffs_within_window(total_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineering_functions = [categorize_navstat, numerize_UN_LOCODE, numerize_ISO] #, apply_markov, minutes_to_etaParsed, categorize_rot, type_dummies\n",
    "\n",
    "\n",
    "feature_engineer = FeatureEngineer(total_df)\n",
    "feature_engineer.apply_features(feature_engineering_functions)\n",
    "total_df = feature_engineer.get_dataframe()\n",
    "\n",
    "total_df.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_non_numeric_columns(df):\n",
    "    # Select columns that are either of type bool, float, or int\n",
    "    df = df.select_dtypes(include=['bool', 'float', 'int'])\n",
    "    return df\n",
    "\n",
    "total_df = remove_non_numeric_columns(total_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       cog   sog  rot  heading  navstat  latitude  longitude  \\\n",
      "time                                                                           \n",
      "2024-01-12 14:07:47  308.1  17.1   -6      316        0   7.50361   77.58340   \n",
      "2024-01-12 14:31:00  307.6  17.3    5      313        0   7.57302   77.49505   \n",
      "2024-01-12 14:57:23  306.8  16.9    5      312        0   7.65043   77.39404   \n",
      "2024-01-12 15:18:48  307.9  16.9    6      313        0   7.71275   77.31394   \n",
      "2024-01-12 15:39:47  307.0  16.3    7      313        0   7.77191   77.23585   \n",
      "\n",
      "                     portLongitude  portLatitude   CEU  ...  rampCapacity  \\\n",
      "time                                                    ...                 \n",
      "2024-01-12 14:07:47      80.341111     13.263333  6500  ...         150.0   \n",
      "2024-01-12 14:31:00      72.885278     18.941944  6500  ...         150.0   \n",
      "2024-01-12 14:57:23      72.885278     18.941944  6500  ...         150.0   \n",
      "2024-01-12 15:18:48      72.885278     18.941944  6500  ...         150.0   \n",
      "2024-01-12 15:39:47      72.885278     18.941944  6500  ...         150.0   \n",
      "\n",
      "                     yearBuilt  diff_seconds  diff_minutes  diff_hours  \\\n",
      "time                                                                     \n",
      "2024-01-12 14:07:47       2000        1393.0     23.216667    0.386944   \n",
      "2024-01-12 14:31:00       2000        1583.0     26.383333    0.439722   \n",
      "2024-01-12 14:57:23       2000        1285.0     21.416667    0.356944   \n",
      "2024-01-12 15:18:48       2000        1259.0     20.983333    0.349722   \n",
      "2024-01-12 15:39:47       2000         901.0     15.016667    0.250278   \n",
      "\n",
      "                     diff_days  next_latitude  next_longitude  UN_LOCODE_num  \\\n",
      "time                                                                           \n",
      "2024-01-12 14:07:47   0.016123        7.57302        77.49505              0   \n",
      "2024-01-12 14:31:00   0.018322        7.65043        77.39404              1   \n",
      "2024-01-12 14:57:23   0.014873        7.71275        77.31394              1   \n",
      "2024-01-12 15:18:48   0.014572        7.77191        77.23585              1   \n",
      "2024-01-12 15:39:47   0.010428        7.81285        77.18147              1   \n",
      "\n",
      "                     ISO_num  \n",
      "time                          \n",
      "2024-01-12 14:07:47        0  \n",
      "2024-01-12 14:31:00        0  \n",
      "2024-01-12 14:57:23        0  \n",
      "2024-01-12 15:18:48        0  \n",
      "2024-01-12 15:39:47        0  \n",
      "\n",
      "[5 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(total_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(df, perc1, perc2):\n",
    "\n",
    "    y_list = ['next_latitude', 'next_longitude'] #'next_latitude', 'next_longitude'\n",
    "    ys = df[y_list]\n",
    "    Xs = df.drop(columns = y_list)\n",
    "\n",
    "    X_train = Xs.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    y_train = ys.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    X_val = Xs.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    y_val = ys.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    X_test = Xs.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "    y_test = ys.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(total_df, 0.85, 0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cols= X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       cog   sog  rot  heading  navstat  latitude  longitude  \\\n",
      "time                                                                           \n",
      "2024-01-12 14:07:47  308.1  17.1   -6      316        0   7.50361   77.58340   \n",
      "2024-01-12 14:31:00  307.6  17.3    5      313        0   7.57302   77.49505   \n",
      "2024-01-12 14:57:23  306.8  16.9    5      312        0   7.65043   77.39404   \n",
      "2024-01-12 15:18:48  307.9  16.9    6      313        0   7.71275   77.31394   \n",
      "2024-01-12 15:39:47  307.0  16.3    7      313        0   7.77191   77.23585   \n",
      "...                    ...   ...  ...      ...      ...       ...        ...   \n",
      "2024-03-17 20:51:50  308.0  19.7    0      308        0  41.46054   12.36343   \n",
      "2024-03-17 21:08:09  325.3  19.1    0      325        0  41.52613   12.28797   \n",
      "2024-03-17 21:35:38  311.3  19.6    0      312        0  41.63601   12.15595   \n",
      "2024-03-17 21:55:50  312.9  19.6    0      314        0  41.70853   12.04483   \n",
      "2024-03-17 22:17:02  312.3  19.8    0      314        0  41.78789   11.93096   \n",
      "\n",
      "                     portLongitude  portLatitude   CEU  ...  maxSpeed  \\\n",
      "time                                                    ...             \n",
      "2024-01-12 14:07:47      80.341111     13.263333  6500  ...      18.6   \n",
      "2024-01-12 14:31:00      72.885278     18.941944  6500  ...      18.6   \n",
      "2024-01-12 14:57:23      72.885278     18.941944  6500  ...      18.6   \n",
      "2024-01-12 15:18:48      72.885278     18.941944  6500  ...      18.6   \n",
      "2024-01-12 15:39:47      72.885278     18.941944  6500  ...      18.6   \n",
      "...                            ...           ...   ...  ...       ...   \n",
      "2024-03-17 20:51:50      12.967000     40.900000   720  ...       NaN   \n",
      "2024-03-17 21:08:09      11.780833     42.098889   720  ...       NaN   \n",
      "2024-03-17 21:35:38      11.780833     42.098889   720  ...       NaN   \n",
      "2024-03-17 21:55:50      11.780833     42.098889   720  ...       NaN   \n",
      "2024-03-17 22:17:02      11.780833     42.098889   720  ...       NaN   \n",
      "\n",
      "                     maxWidth  rampCapacity  yearBuilt  diff_seconds  \\\n",
      "time                                                                   \n",
      "2024-01-12 14:07:47      15.2         150.0       2000        1393.0   \n",
      "2024-01-12 14:31:00      15.2         150.0       2000        1583.0   \n",
      "2024-01-12 14:57:23      15.2         150.0       2000        1285.0   \n",
      "2024-01-12 15:18:48      15.2         150.0       2000        1259.0   \n",
      "2024-01-12 15:39:47      15.2         150.0       2000         901.0   \n",
      "...                       ...           ...        ...           ...   \n",
      "2024-03-17 20:51:50       NaN           NaN       2010         979.0   \n",
      "2024-03-17 21:08:09       NaN           NaN       2010        1649.0   \n",
      "2024-03-17 21:35:38       NaN           NaN       2010        1212.0   \n",
      "2024-03-17 21:55:50       NaN           NaN       2010        1272.0   \n",
      "2024-03-17 22:17:02       NaN           NaN       2010         582.0   \n",
      "\n",
      "                     diff_minutes  diff_hours  diff_days  UN_LOCODE_num  \\\n",
      "time                                                                      \n",
      "2024-01-12 14:07:47     23.216667    0.386944   0.016123              0   \n",
      "2024-01-12 14:31:00     26.383333    0.439722   0.018322              1   \n",
      "2024-01-12 14:57:23     21.416667    0.356944   0.014873              1   \n",
      "2024-01-12 15:18:48     20.983333    0.349722   0.014572              1   \n",
      "2024-01-12 15:39:47     15.016667    0.250278   0.010428              1   \n",
      "...                           ...         ...        ...            ...   \n",
      "2024-03-17 20:51:50     16.316667    0.271944   0.011331            499   \n",
      "2024-03-17 21:08:09     27.483333    0.458056   0.019086            495   \n",
      "2024-03-17 21:35:38     20.200000    0.336667   0.014028            495   \n",
      "2024-03-17 21:55:50     21.200000    0.353333   0.014722            495   \n",
      "2024-03-17 22:17:02      9.700000    0.161667   0.006736            495   \n",
      "\n",
      "                     ISO_num  \n",
      "time                          \n",
      "2024-01-12 14:07:47        0  \n",
      "2024-01-12 14:31:00        0  \n",
      "2024-01-12 14:57:23        0  \n",
      "2024-01-12 15:18:48        0  \n",
      "2024-01-12 15:39:47        0  \n",
      "...                      ...  \n",
      "2024-03-17 20:51:50       31  \n",
      "2024-03-17 21:08:09       31  \n",
      "2024-03-17 21:35:38       31  \n",
      "2024-03-17 21:55:50       31  \n",
      "2024-03-17 22:17:02       31  \n",
      "\n",
      "[1291798 rows x 32 columns]\n",
      "<xgboost.core.DMatrix object at 0x000001337747A890>\n",
      "[0]\tvalidation-rmse:3.09966\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest_X = xgb.DMatrix(X_test)\n",
    "\n",
    "params = {\"objective\": \"reg:squarederror\",\n",
    "            \"max_depth\": 7,\n",
    "            \"booster\": \"gbtree\",\n",
    "            \"tree-method\": \"gpu_hist\",\n",
    "            \"colsample_bynode\": 0.4,\n",
    "            \"num_parallel_tree\": 50,\n",
    "            \"subsample\": 0.6,\n",
    "            \"seed\": 42,\n",
    "            \"learning_rate\": 1,\n",
    "            #\"n_estimators\": 100,\n",
    "            #\"reg_alpha\": 0.1,\n",
    "            #\"reg_lambda\": 0.1,\n",
    "            #\"n_jobs\": -1,\n",
    "            \"verbosity\": 1\n",
    "            }\n",
    "\n",
    "#Subsample was 0.8, num-parallel tree was 100, colsample-bynode was 0.5 and max-depth was 5. Before tuning. \n",
    "\n",
    "#After first round of tuning we got sumbsample was 0.6, num-parallel tree was 50, colsample-bynode was 0.4 and max-depth was 7. Before tuning. \n",
    "\n",
    "num_boost_round = 30\n",
    "\n",
    "#Tried 50, but that stagnated quickly. So reducing again to 30.  \n",
    "\n",
    "\n",
    "early_stopping_rounds = 3\n",
    "\n",
    "print(dtrain)\n",
    "\n",
    "model = xgb.train(params, dtrain, num_boost_round, evals=[(dval, \"validation\")], \n",
    "                  early_stopping_rounds=early_stopping_rounds, verbose_eval=True)\n",
    "\n",
    "\n",
    "preds = model.predict(dtest_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_time_diff_with_last_rows(test_df, last_rows):\n",
    "    # Merge test_df with last_rows on vesselId to get the last row time for each vesselId\n",
    "    merged_df = pd.merge(\n",
    "        test_df[[\"ID\", \"vesselId\", \"time\"]],\n",
    "        last_rows,\n",
    "        on='vesselId',\n",
    "        suffixes=('', '_last')\n",
    "    )\n",
    "    print(merged_df.columns)\n",
    "    # Calculate time difference between test_df time and last row time\n",
    "    merged_df['time_diff'] = (merged_df['time'] - merged_df['time_last']).dt.total_seconds()\n",
    "    \n",
    "    # Create columns for each time unit by converting from seconds\n",
    "    merged_df['diff_seconds'] = merged_df['time_diff']\n",
    "    merged_df['diff_minutes'] = merged_df['time_diff'] / 60\n",
    "    merged_df['diff_hours'] = merged_df['time_diff'] / 3600\n",
    "    merged_df['diff_days'] = merged_df['time_diff'] / 86400\n",
    "    \n",
    "    # Drop the temporary 'time_diff' column and 'time_last' if desired\n",
    "    merged_df = merged_df.drop(columns=['time_diff', 'time_last'])\n",
    "    \n",
    "    \n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = parser.retrieve_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                  vesselId                time  scaling_factor\n",
      "0   0  61e9f3aeb937134a3c4bfe3d 2024-05-08 00:03:16             0.3\n",
      "1   1  61e9f473b937134a3c4c02df 2024-05-08 00:06:17             0.3\n",
      "2   2  61e9f469b937134a3c4c029b 2024-05-08 00:10:02             0.3\n",
      "3   3  61e9f45bb937134a3c4c0221 2024-05-08 00:10:34             0.3\n",
      "4   4  61e9f38eb937134a3c4bfd8d 2024-05-08 00:12:27             0.3\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   time    cog   sog  rot  heading  navstat  latitude  \\\n",
      "0   2024-05-05 13:25:50   40.0   0.0    1      328        1  36.84686   \n",
      "1   2024-05-07 23:51:29  291.0   0.3    0      275        2  48.53320   \n",
      "2   2024-05-07 21:53:14  129.3  15.6    0      128        0  28.82071   \n",
      "3   2024-05-05 04:33:43  303.7  10.0   -2      303        0  33.86918   \n",
      "4   2024-05-07 23:42:38   38.9  15.5    3       40        0  33.18068   \n",
      "..                  ...    ...   ...  ...      ...      ...       ...   \n",
      "683 2024-05-07 20:04:21   45.8   0.0    0      150        5 -34.06421   \n",
      "684 2024-05-07 23:59:04   27.6  16.0    0       28        0  54.71940   \n",
      "685 2024-05-01 11:34:29  182.0  15.0    0      182        0  33.96570   \n",
      "686 2024-05-07 23:54:24   51.0   0.0    0       51        5  51.35306   \n",
      "687 2024-05-07 23:59:01   53.6  17.7   -1       51        0  59.89167   \n",
      "\n",
      "     longitude                   vesselId                    portId  ...  \\\n",
      "0      5.84638   61e9f38eb937134a3c4bfd8b  61d36ee00a1807568ff9a072  ...   \n",
      "1     -6.12003   61e9f38eb937134a3c4bfd8d  61d3743d3aeaecc07011a6fa  ...   \n",
      "2   -120.46513   61e9f38eb937134a3c4bfd8f  61d37ab61366c3998241d9f4  ...   \n",
      "3   -118.81433   61e9f38eb937134a3c4bfd91  61d37a1d1366c3998241d91e  ...   \n",
      "4     -9.43055   61e9f390b937134a3c4bfd93  61d38259b7b7526e1adf3a41  ...   \n",
      "..         ...                        ...                       ...  ...   \n",
      "683  -59.03513  clh6aqawa0003gh0zu0aznvt2  61d36f210a1807568ff9a0c3  ...   \n",
      "684   12.46165  clh6aqawa0004gh0z12aogec9  634c4de270937fc01c3a71cf  ...   \n",
      "685  134.93027  clh6aqawa0005gh0z64y4xyip  61d37a091366c3998241d8f6  ...   \n",
      "686    3.19241  clh6aqawa0006gh0zje911dl3  61d36f9a0a1807568ff9a156  ...   \n",
      "687   21.54685  clh6aqawa0007gh0z9h6zi9bo  61d373b83aeaecc07011a62b  ...   \n",
      "\n",
      "    enginePower freshWater     fuel      homePort  length maxHeight  maxSpeed  \\\n",
      "0           0.0        NaN      NaN          OSLO  199.00       5.0      18.6   \n",
      "1       14220.0        NaN      NaN      MONROVIA  182.00       NaN       NaN   \n",
      "2       14220.0        NaN      NaN  SAINT JOHN'S  182.00       NaN       NaN   \n",
      "3       11060.0        NaN      NaN           NaN  167.00       NaN       NaN   \n",
      "4       13140.0     491.47  3236.78        Panama  199.98       NaN       NaN   \n",
      "..          ...        ...      ...           ...     ...       ...       ...   \n",
      "683         NaN        NaN      NaN           NaN  200.00       NaN       NaN   \n",
      "684         NaN        NaN      NaN           NaN  177.00       NaN       NaN   \n",
      "685         NaN        NaN      NaN           NaN  200.00       NaN       NaN   \n",
      "686         NaN        NaN      NaN           NaN  191.00       NaN       NaN   \n",
      "687         NaN        NaN      NaN           NaN  191.00       NaN       NaN   \n",
      "\n",
      "     maxWidth  rampCapacity  yearBuilt  \n",
      "0        15.2         150.0       2000  \n",
      "1         NaN           NaN       2006  \n",
      "2         NaN           NaN       2010  \n",
      "3         NaN           NaN       2011  \n",
      "4         NaN           NaN       2018  \n",
      "..        ...           ...        ...  \n",
      "683       NaN           NaN       2014  \n",
      "684       NaN           NaN       1989  \n",
      "685       NaN           NaN       2002  \n",
      "686       NaN           NaN       2007  \n",
      "687       NaN           NaN       2017  \n",
      "\n",
      "[688 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(last_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'vesselId', 'time', 'time_last', 'cog', 'sog', 'rot', 'heading',\n",
      "       'navstat', 'latitude', 'longitude', 'portId', 'etaParsed', 'UN_LOCODE',\n",
      "       'ISO', 'portLongitude', 'portLatitude', 'shippingLineId', 'CEU', 'DWT',\n",
      "       'GT', 'NT', 'vesselType', 'breadth', 'depth', 'draft', 'enginePower',\n",
      "       'freshWater', 'fuel', 'homePort', 'length', 'maxHeight', 'maxSpeed',\n",
      "       'maxWidth', 'rampCapacity', 'yearBuilt'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "test_df=calculate_time_diff_with_last_rows(test_df,last_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ID', 'vesselId', 'time', 'cog', 'sog', 'rot', 'heading', 'navstat',\n",
      "       'latitude', 'longitude', 'portId', 'etaParsed', 'UN_LOCODE', 'ISO',\n",
      "       'portLongitude', 'portLatitude', 'shippingLineId', 'CEU', 'DWT', 'GT',\n",
      "       'NT', 'vesselType', 'breadth', 'depth', 'draft', 'enginePower',\n",
      "       'freshWater', 'fuel', 'homePort', 'length', 'maxHeight', 'maxSpeed',\n",
      "       'maxWidth', 'rampCapacity', 'yearBuilt', 'diff_seconds', 'diff_minutes',\n",
      "       'diff_hours', 'diff_days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_engineer = FeatureEngineer(test_df)\n",
    "feature_engineer.apply_features(feature_engineering_functions)\n",
    "test_df = feature_engineer.get_dataframe()\n",
    "\n",
    "test_df.set_index(\"time\", inplace=True)\n",
    "test_df = remove_non_numeric_columns(test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ID    cog   sog  rot  heading  navstat  latitude  \\\n",
      "time                                                                    \n",
      "2024-05-08 00:03:16   0  179.6   0.0    0      344        5  31.14647   \n",
      "2024-05-08 00:06:17   1   24.7   0.0    0      214        5  14.81694   \n",
      "2024-05-08 00:10:02   2    8.0  18.7    0        6        0  38.27895   \n",
      "2024-05-08 00:10:34   3  321.3   0.1    0       70        1 -43.53785   \n",
      "2024-05-08 00:12:27   4  291.0   0.3    0      275        2  48.53320   \n",
      "\n",
      "                     longitude  portLongitude  portLatitude  ...  maxSpeed  \\\n",
      "time                                                         ...             \n",
      "2024-05-08 00:03:16  -81.49789     -81.496667     31.140556  ...       NaN   \n",
      "2024-05-08 00:06:17  120.29625     120.279444     14.808333  ...       NaN   \n",
      "2024-05-08 00:10:02   10.78280      11.780833     42.098889  ...       NaN   \n",
      "2024-05-08 00:10:34  172.83522     172.716111    -43.606111  ...      22.2   \n",
      "2024-05-08 00:12:27   -6.12003      -4.474167     48.380556  ...       NaN   \n",
      "\n",
      "                     maxWidth  rampCapacity  yearBuilt  diff_seconds  \\\n",
      "time                                                                   \n",
      "2024-05-08 00:03:16       NaN           NaN       2011         900.0   \n",
      "2024-05-08 00:06:17       NaN           NaN       2012         541.0   \n",
      "2024-05-08 00:10:02       NaN           NaN       2003         654.0   \n",
      "2024-05-08 00:10:34       NaN           NaN       2011        1080.0   \n",
      "2024-05-08 00:12:27       NaN           NaN       2006        1258.0   \n",
      "\n",
      "                     diff_minutes  diff_hours  diff_days  UN_LOCODE_num  \\\n",
      "time                                                                      \n",
      "2024-05-08 00:03:16     15.000000    0.250000   0.010417              0   \n",
      "2024-05-08 00:06:17      9.016667    0.150278   0.006262              1   \n",
      "2024-05-08 00:10:02     10.900000    0.181667   0.007569              2   \n",
      "2024-05-08 00:10:34     18.000000    0.300000   0.012500              3   \n",
      "2024-05-08 00:12:27     20.966667    0.349444   0.014560              4   \n",
      "\n",
      "                     ISO_num  \n",
      "time                          \n",
      "2024-05-08 00:03:16        0  \n",
      "2024-05-08 00:06:17        1  \n",
      "2024-05-08 00:10:02        2  \n",
      "2024-05-08 00:10:34        3  \n",
      "2024-05-08 00:12:27        4  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model, input_df):\n",
    "    # Extract the features for prediction, excluding the 'ID' column\n",
    "    features_df = input_df.drop(columns=['ID'])\n",
    "    features_df = features_df[X_train_cols]\n",
    "    # Generate predictions using the model\n",
    "    predictions = model.predict(xgb.DMatrix(features_df))\n",
    "    \n",
    "    # Create a DataFrame with the predictions, renaming columns as required\n",
    "    predictions_df = pd.DataFrame(predictions, columns=['next_latitude', 'next_longitude'])\n",
    "    predictions_df = predictions_df.rename(columns={'next_latitude': 'latitude', 'next_longitude': 'longitude'})\n",
    "    \n",
    "    # Combine the 'ID' column with the predictions DataFrame\n",
    "    result_df = pd.concat([input_df['ID'].reset_index(drop=True), predictions_df], axis=1)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = make_predictions(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(RESOURCE_FOLDER+\"/result_simple.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
