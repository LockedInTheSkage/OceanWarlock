{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: tensorflow in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.17.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.17.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow) (2.17.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.25.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\bruker\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (4.9.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.65.4)\n",
      "Requirement already satisfied: tensorboard<2.18,>=2.17 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (2.17.0)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorflow-intel==2.17.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.17.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.12.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.17.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow-intel==2.17.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\bruker\\appdata\\roaming\\python\\python311\\site-packages (from rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (2.16.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow-intel==2.17.0->tensorflow) (0.1.2)\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\bruker\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\bruker\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in c:\\users\\bruker\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow\n",
    "%pip install pandas \n",
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import datetime\n",
    "import os\n",
    "from feature_engineering.tensor_features import develop_features, floating_conv\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from data_handler import LocalToLargeDataLoader\n",
    "from path_finder import path_sorter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving training data...\n"
     ]
    }
   ],
   "source": [
    "data_loader = LocalToLargeDataLoader(print_progress=True)\n",
    "parsed_data = data_loader.load_raw_data(path=\"../../resources\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['time', 'cog', 'sog', 'rot', 'heading', 'navstat', 'latitude',\n",
      "       'longitude', 'vesselId', 'portId', 'etaParsed'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(parsed_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===================-] 100.0% complete\n",
      "[====================] 100.0% complete\n",
      "Concatting dataframes\n"
     ]
    }
   ],
   "source": [
    "path_dict = path_sorter(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rot', 'heading', 'navstat', 'vesselId', 'portId', 'etaParsed', 'time_key', 'group_id', 'time_0', 'cog_0', 'sog_0', 'latitude_0', 'longitude_0', 'time_1', 'cog_1', 'sog_1', 'latitude_1', 'longitude_1', 'time_2', 'cog_2', 'sog_2', 'latitude_2', 'longitude_2', 'time_3', 'cog_3', 'sog_3', 'latitude_3', 'longitude_3', 'time_4', 'cog_4', 'sog_4', 'latitude_4', 'longitude_4', 'time_5', 'cog_5', 'sog_5', 'latitude_5', 'longitude_5', 'time_6', 'cog_6', 'sog_6', 'latitude_6', 'longitude_6', 'time_7', 'cog_7', 'sog_7', 'latitude_7', 'longitude_7', 'time_8', 'cog_8', 'sog_8', 'latitude_8', 'longitude_8', 'time_9', 'cog_9', 'sog_9', 'latitude_9', 'longitude_9']\n",
      "2024-05-05 13:25:50\n",
      "0         1\n",
      "1         0\n",
      "2         0\n",
      "3         0\n",
      "4         0\n",
      "         ..\n",
      "152527    0\n",
      "152528    0\n",
      "152529    5\n",
      "152530    0\n",
      "152531    0\n",
      "Name: navstat, Length: 152532, dtype: int64\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(list(path_dict.keys()))\n",
    "print(path_dict[\"time_key\"][0])\n",
    "print(path_dict['navstat'])\n",
    "print(path_dict[list(path_dict.keys())[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting into tests and training data\n"
     ]
    }
   ],
   "source": [
    "features, y, test_features, y_test = data_loader.load_training_data(path_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Developing features with the following columns:  Index(['rot', 'heading', 'navstat', 'etaParsed', 'time_0', 'time_1', 'cog_1',\n",
      "       'sog_1', 'latitude_1', 'longitude_1', 'time_2', 'cog_2', 'sog_2',\n",
      "       'latitude_2', 'longitude_2', 'time_3', 'cog_3', 'sog_3', 'latitude_3',\n",
      "       'longitude_3', 'time_4', 'cog_4', 'sog_4', 'latitude_4', 'longitude_4',\n",
      "       'time_5', 'cog_5', 'sog_5', 'latitude_5', 'longitude_5', 'time_6',\n",
      "       'cog_6', 'sog_6', 'latitude_6', 'longitude_6', 'time_7', 'cog_7',\n",
      "       'sog_7', 'latitude_7', 'longitude_7', 'time_8', 'cog_8', 'sog_8',\n",
      "       'latitude_8', 'longitude_8', 'time_9', 'cog_9', 'sog_9', 'latitude_9',\n",
      "       'longitude_9'],\n",
      "      dtype='object')\n",
      "Developing features with the following columns:  Index(['rot', 'heading', 'navstat', 'etaParsed', 'time_0', 'time_1', 'cog_1',\n",
      "       'sog_1', 'latitude_1', 'longitude_1', 'time_2', 'cog_2', 'sog_2',\n",
      "       'latitude_2', 'longitude_2', 'time_3', 'cog_3', 'sog_3', 'latitude_3',\n",
      "       'longitude_3', 'time_4', 'cog_4', 'sog_4', 'latitude_4', 'longitude_4',\n",
      "       'time_5', 'cog_5', 'sog_5', 'latitude_5', 'longitude_5', 'time_6',\n",
      "       'cog_6', 'sog_6', 'latitude_6', 'longitude_6', 'time_7', 'cog_7',\n",
      "       'sog_7', 'latitude_7', 'longitude_7', 'time_8', 'cog_8', 'sog_8',\n",
      "       'latitude_8', 'longitude_8', 'time_9', 'cog_9', 'sog_9', 'latitude_9',\n",
      "       'longitude_9'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "features=develop_features(features)\n",
    "test_features=develop_features(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rot', 'heading', 'navstat', 'etaParsed', 'time_0', 'time_1', 'cog_1', 'sog_1', 'latitude_1', 'longitude_1', 'time_2', 'cog_2', 'sog_2', 'latitude_2', 'longitude_2', 'time_3', 'cog_3', 'sog_3', 'latitude_3', 'longitude_3', 'time_4', 'cog_4', 'sog_4', 'latitude_4', 'longitude_4', 'time_5', 'cog_5', 'sog_5', 'latitude_5', 'longitude_5', 'time_6', 'cog_6', 'sog_6', 'latitude_6', 'longitude_6', 'time_7', 'cog_7', 'sog_7', 'latitude_7', 'longitude_7', 'time_8', 'cog_8', 'sog_8', 'latitude_8', 'longitude_8', 'time_9', 'cog_9', 'sog_9', 'latitude_9', 'longitude_9']\n",
      "50\n",
      "        latitude_0  longitude_0\n",
      "39974     49.16460   -123.92530\n",
      "3942      13.06485    100.88147\n",
      "14723     32.90688    -79.95385\n",
      "73623     41.53984    140.65908\n",
      "100269     1.31259    104.32622\n"
     ]
    }
   ],
   "source": [
    "print(list(features.keys()))\n",
    "print(len(list(features.keys())))\n",
    "# print(features.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = features.to_numpy()\n",
    "X_test_np = test_features.to_numpy()\n",
    "y_train = y.to_numpy()\n",
    "y_test_np = y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Input layer\n",
    "input_dim = X_train.shape[1]  # Number of features in your dataset\n",
    "\n",
    "# Add layers\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))  # First hidden layer\n",
    "model.add(Dropout(0.3))  # Dropout for regularization\n",
    "model.add(Dense(32, activation='relu'))  # Second hidden layer\n",
    "model.add(Dense(16, activation='relu'))  # Third hidden layer\n",
    "\n",
    "# Output layer\n",
    "# If it's a regression task (predicting a continuous variable like time):\n",
    "model.add(Dense(units=2, activation='linear')) \n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='mean_squared_error', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'input_shape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m parameters\u001b[38;5;241m=\u001b[39m(\u001b[43minput_shape\u001b[49m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(parameters)\n\u001b[0;32m      3\u001b[0m layer_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'input_shape' is not defined"
     ]
    }
   ],
   "source": [
    "# parameters=(input_shape[0])\n",
    "# print(parameters)\n",
    "# layer_n=2\n",
    "# layer=[\n",
    "#         tf.keras.layers.Normalization(),\n",
    "#         tf.keras.layers.Dense(parameters//layer_n+1, activation='relu'),\n",
    "#         tf.keras.layers.Dropout(0.2)\n",
    "#         ]\n",
    "\n",
    "# model_list=[tf.keras.Input(shape=input_shape),\n",
    "#             tf.keras.layers.Dense(input_shape[0], activation='relu')]\n",
    "# model_list.extend(layer*layer_n)\n",
    "# model_list.append(tf.keras.layers.Dense(2, activation='linear'))\n",
    "# print(model_list)\n",
    "# model = tf.keras.models.Sequential(model_list)\n",
    "\n",
    "# model.compile(optimizer='adam',\n",
    "#   loss='mean_squared_error',\n",
    "#   metrics=['mae','mape'])\n",
    "\n",
    "# model.summary()\n",
    "\n",
    "# early_stopping = EarlyStopping(\n",
    "#     monitor='val_loss',  # You can change this to 'val_accuracy' or another metric\n",
    "#     patience=5,          # Number of epochs to wait for improvement\n",
    "#     restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored quantity\n",
    "# )\n",
    "\n",
    "# checkpoint = ModelCheckpoint(\n",
    "#     filepath='modelepoch{epoch:02d}val_loss{val_loss:.2f}.keras',\n",
    "#     monitor='val_loss',\n",
    "#     save_best_only=True,\n",
    "#     save_weights_only=False,\n",
    "#     mode='min',\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# log_dir= os.path.join('logs','fit',datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),)\n",
    "# # tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Define callbacks\u001b[39;00m\n\u001b[0;32m      4\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 5\u001b[0m model_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mModelCheckpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Bruker\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\callbacks\\model_checkpoint.py:191\u001b[0m, in \u001b[0;36mModelCheckpoint.__init__\u001b[1;34m(self, filepath, monitor, verbose, save_best_only, save_weights_only, mode, save_freq, initial_value_threshold)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 191\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    192\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe filepath provided must end in `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    193\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(Keras model format). Received: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    194\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    195\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The filepath provided must end in `.keras` (Keras model format). Received: filepath=best_model.h5"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.keras', save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y data samples [[  36.84686    5.84638]\n",
      " [  48.5332    -6.12003]\n",
      " [  28.82071 -120.46513]\n",
      " [  33.86918 -118.81433]\n",
      " [  33.18068   -9.43055]]\n",
      "Epoch 1/20\n",
      "\u001b[1m 8/14\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 28622121336832.0000 - mae: 4240309.5000 - mape: 38419712.0000  \n",
      "Epoch 1: val_loss did not improve from 23641094144.00000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 25887286231040.0000 - mae: 4034683.5000 - mape: 36272012.0000 - val_loss: 775497777152.0000 - val_mae: 811846.8125 - val_mape: 10468310.0000\n",
      "Epoch 2/20\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 22770285019136.0000 - mae: 4008617.0000 - mape: 17482132.0000\n",
      "Epoch 2: val_loss did not improve from 23641094144.00000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 18431774556160.0000 - mae: 3425951.7500 - mape: 25047640.0000 - val_loss: 110672863232.0000 - val_mae: 282489.5000 - val_mape: 3566033.5000\n",
      "Epoch 3/20\n",
      "\u001b[1m13/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 10771739181056.0000 - mae: 2604610.0000 - mape: 21291736.0000  \n",
      "Epoch 3: val_loss did not improve from 23641094144.00000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - loss: 10633156231168.0000 - mae: 2590863.5000 - mape: 21655108.0000 - val_loss: 82718629888.0000 - val_mae: 243285.0938 - val_mape: 3099174.0000\n",
      "Epoch 4/20\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6807864999936.0000 - mae: 2028861.0000 - mape: 17263594.0000 \n",
      "Epoch 4: val_loss did not improve from 23641094144.00000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 6747755905024.0000 - mae: 2020659.1250 - mape: 17583964.0000 - val_loss: 84444209152.0000 - val_mae: 279073.3438 - val_mape: 3285968.5000\n",
      "Epoch 5/20\n",
      "\u001b[1m 1/14\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 4252171239424.0000 - mae: 1660859.2500 - mape: 5523486.0000\n",
      "Epoch 5: val_loss did not improve from 23641094144.00000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 3566041825280.0000 - mae: 1504422.6250 - mape: 11392523.0000 - val_loss: 31243094016.0000 - val_mae: 138401.1719 - val_mape: 1842424.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1883b930e10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, \n",
    "                    validation_split=0.2, callbacks=[early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(X_test_np, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
