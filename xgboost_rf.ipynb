{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas._libs.tslibs.timestamps.Timestamp'>\n"
     ]
    }
   ],
   "source": [
    "#We have two resampled and therefore regular datasets, now we need to make our time series into a supervised problem.\n",
    "#First I need to change navstat into a categorical feature:\n",
    "\n",
    "\n",
    "# Define categories based on ranges or discrete values\n",
    "# pretty_20m = pd.read_csv(\"../Project materials(1)/resampled_data_20min.csv\")\n",
    "\n",
    "pretty_h = pd.read_csv(\"../Project materials(1)/resampled_data_h.csv\")\n",
    "\n",
    "pretty_h['etaParsed'] = pd.to_datetime(pretty_h['etaParsed'])\n",
    "pretty_h[\"time\"] = pd.to_datetime(pretty_h['time'])\n",
    "\n",
    "start_date = pd.to_datetime('2024-01-01')\n",
    "\n",
    "pretty_h[\"etaParsed\"] = (pretty_h['etaParsed'] - start_date).dt.days\n",
    "\n",
    "navstat_unique = pretty_h[\"navstat\"].unique()\n",
    "\n",
    "#pretty_20m[\"navstat\"] = pd.Categorical(pretty_20m[\"navstat\"], categories=navstat_unique, ordered=True)\n",
    "\n",
    "pretty_h[\"navstat\"] = pd.Categorical(pretty_h[\"navstat\"], categories=navstat_unique, ordered=True)\n",
    "\n",
    "\n",
    "# Let's make dummys \n",
    "\n",
    "pretty_h = pd.get_dummies(pretty_h, columns=[\"navstat\"], drop_first=True)\n",
    "navstat_cols = [col for col in pretty_h.columns if col.startswith(\"navstat\")]\n",
    "pretty_h[navstat_cols]=pretty_h[navstat_cols].astype(int)\n",
    "    \n",
    "\n",
    "#pretty_20m = pd.get_dummies(pretty_20m, columns = [\"navstat\"], drop_first=True)\n",
    "print(type(pretty_h[\"time\"].iloc[1]))\n",
    "#pretty_20m.set_index(\"time\", inplace=True)\n",
    "pretty_h.set_index(\"time\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pretty_h[\"etaParsed\"].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cog_t-3', 'cog_t-2', 'cog_t-1', 'cog_t', 'sog_t-3', 'sog_t-2',\n",
       "       'sog_t-1', 'sog_t', 'rot_t-3', 'rot_t-2', 'rot_t-1', 'rot_t',\n",
       "       'heading_t-3', 'heading_t-2', 'heading_t-1', 'heading_t',\n",
       "       'latitude_t-3', 'latitude_t-2', 'latitude_t-1', 'latitude_t',\n",
       "       'longitude_t-3', 'longitude_t-2', 'longitude_t-1', 'longitude_t',\n",
       "       'etaParsed_t-3', 'etaParsed_t-2', 'etaParsed_t-1', 'etaParsed_t',\n",
       "       'portLongitude_t-3', 'portLongitude_t-2', 'portLongitude_t-1',\n",
       "       'portLongitude_t', 'portLatitude_t-3', 'portLatitude_t-2',\n",
       "       'portLatitude_t-1', 'portLatitude_t', 'navstat_5.0_t-3',\n",
       "       'navstat_5.0_t-2', 'navstat_5.0_t-1', 'navstat_5.0_t',\n",
       "       'navstat_1.0_t-3', 'navstat_1.0_t-2', 'navstat_1.0_t-1',\n",
       "       'navstat_1.0_t', 'navstat_8.0_t-3', 'navstat_8.0_t-2',\n",
       "       'navstat_8.0_t-1', 'navstat_8.0_t', 'navstat_2.0_t-3',\n",
       "       'navstat_2.0_t-2', 'navstat_2.0_t-1', 'navstat_2.0_t',\n",
       "       'navstat_3.0_t-3', 'navstat_3.0_t-2', 'navstat_3.0_t-1',\n",
       "       'navstat_3.0_t', 'navstat_15.0_t-3', 'navstat_15.0_t-2',\n",
       "       'navstat_15.0_t-1', 'navstat_15.0_t', 'navstat_4.0_t-3',\n",
       "       'navstat_4.0_t-2', 'navstat_4.0_t-1', 'navstat_4.0_t',\n",
       "       'navstat_14.0_t-3', 'navstat_14.0_t-2', 'navstat_14.0_t-1',\n",
       "       'navstat_14.0_t', 'navstat_11.0_t-3', 'navstat_11.0_t-2',\n",
       "       'navstat_11.0_t-1', 'navstat_11.0_t', 'navstat_12.0_t-3',\n",
       "       'navstat_12.0_t-2', 'navstat_12.0_t-1', 'navstat_12.0_t',\n",
       "       'navstat_6.0_t-3', 'navstat_6.0_t-2', 'navstat_6.0_t-1',\n",
       "       'navstat_6.0_t', 'navstat_7.0_t-3', 'navstat_7.0_t-2',\n",
       "       'navstat_7.0_t-1', 'navstat_7.0_t', 'navstat_13.0_t-3',\n",
       "       'navstat_13.0_t-2', 'navstat_13.0_t-1', 'navstat_13.0_t',\n",
       "       'navstat_9.0_t-3', 'navstat_9.0_t-2', 'navstat_9.0_t-1',\n",
       "       'navstat_9.0_t', 'latitude_t+2', 'latitude_t+1', 'longitude_t+2',\n",
       "       'longitude_t+1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make time series into supervised problem\n",
    "def make_supervised(df, forecast_columns, sorting_column, input_window=1, output_window=1):\n",
    "    \"\"\"\n",
    "    Converts a multivariate time series dataframe into a supervised learning problem.\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The original dataframe with time series data.\n",
    "    forecast_columns (list): A list of column names to forecast.\n",
    "    input_window (int): The number of past observations to use as features.\n",
    "    output_window (int): The number of steps to forecast into the future.\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: A new dataframe with supervised learning format.\n",
    "    \"\"\"\n",
    "    # Create a list to hold the transformed value\n",
    "    df_holder = []\n",
    "    \n",
    "    #Put in a for loop here where you iterate over all IDs, to make sure things get correct\n",
    "    unique_sorts = df[sorting_column].unique()\n",
    "\n",
    "    forbidden_cols = [\"vesselId\", \"UN_LOCODE\", \"ISO\", \"portId\"]\n",
    "    \n",
    "    #Iterate through all IDs\n",
    "    for sorts in unique_sorts:\n",
    "        df_supervised = pd.DataFrame()\n",
    "        sort_df = df[df[sorting_column] == sorts]\n",
    "\n",
    "        #Iterate through all columns for input features\n",
    "        for col in sort_df.columns: \n",
    "            if col in forbidden_cols:\n",
    "                    continue\n",
    "            for i in range(input_window, 0, -1):\n",
    "                df_supervised[f\"{col}_t-{i}\"] = sort_df[col].shift(i)\n",
    "            \n",
    "            df_supervised[f\"{col}_t\"] = sort_df[col]\n",
    "            \n",
    "\n",
    "    # Create columns for forecast (target) with forward shift\n",
    "        for col in forecast_columns:\n",
    "            for j in range(output_window, 0,-1):\n",
    "                df_supervised[f\"{col}_t+{j}\"] = sort_df[col].shift(-j)\n",
    "        \n",
    "        df_holder.append(df_supervised)\n",
    "    \n",
    "\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    \n",
    "    for chunk in df_holder:\n",
    "        df_new = pd.concat([df_new, chunk])\n",
    "    # Remove rows with NaN values caused by the shifting process\n",
    "    df_new.dropna(inplace=True)\n",
    "    \n",
    "    return df_new\n",
    "\n",
    "supervised_h = make_supervised(pretty_h, [\"latitude\", \"longitude\"],\"vesselId\" , 3, 2)\n",
    "\n",
    "supervised_h.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorting by time\n",
    "supervised_h = supervised_h.sort_index(ascending = True)\n",
    "\n",
    "#Sorting columns\n",
    "def sort_columns(df):\n",
    "    \n",
    "    # Extract suffixes and assign _t as _t0\n",
    "    columns_with_suffix = []\n",
    "    for col in df.columns:\n",
    "        match = re.search(r\"_t([+-]?\\d*)$\", col)\n",
    "        # If there's no number after _t, treat it as _t0\n",
    "        suffix = int(match.group(1)) if match.group(1) else 0\n",
    "        columns_with_suffix.append((col, suffix))\n",
    "    \n",
    "    # Sort by suffix value (ascending)\n",
    "    sorted_t_columns = [col for col, _ in sorted(columns_with_suffix, key=lambda x: x[1])]\n",
    "    \n",
    "    # Reorder dataframe columns\n",
    "    return df[sorted_t_columns]\n",
    "\n",
    "supervised_h=sort_columns(supervised_h)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['cog_t-3', 'sog_t-3', 'rot_t-3', 'heading_t-3', 'latitude_t-3',\n",
      "       'longitude_t-3', 'etaParsed_t-3', 'portLongitude_t-3',\n",
      "       'portLatitude_t-3', 'navstat_5.0_t-3', 'navstat_1.0_t-3',\n",
      "       'navstat_8.0_t-3', 'navstat_2.0_t-3', 'navstat_3.0_t-3',\n",
      "       'navstat_15.0_t-3', 'navstat_4.0_t-3', 'navstat_14.0_t-3',\n",
      "       'navstat_11.0_t-3', 'navstat_12.0_t-3', 'navstat_6.0_t-3',\n",
      "       'navstat_7.0_t-3', 'navstat_13.0_t-3', 'navstat_9.0_t-3', 'cog_t-2',\n",
      "       'sog_t-2', 'rot_t-2', 'heading_t-2', 'latitude_t-2', 'longitude_t-2',\n",
      "       'etaParsed_t-2', 'portLongitude_t-2', 'portLatitude_t-2',\n",
      "       'navstat_5.0_t-2', 'navstat_1.0_t-2', 'navstat_8.0_t-2',\n",
      "       'navstat_2.0_t-2', 'navstat_3.0_t-2', 'navstat_15.0_t-2',\n",
      "       'navstat_4.0_t-2', 'navstat_14.0_t-2', 'navstat_11.0_t-2',\n",
      "       'navstat_12.0_t-2', 'navstat_6.0_t-2', 'navstat_7.0_t-2',\n",
      "       'navstat_13.0_t-2', 'navstat_9.0_t-2', 'cog_t-1', 'sog_t-1', 'rot_t-1',\n",
      "       'heading_t-1', 'latitude_t-1', 'longitude_t-1', 'etaParsed_t-1',\n",
      "       'portLongitude_t-1', 'portLatitude_t-1', 'navstat_5.0_t-1',\n",
      "       'navstat_1.0_t-1', 'navstat_8.0_t-1', 'navstat_2.0_t-1',\n",
      "       'navstat_3.0_t-1', 'navstat_15.0_t-1', 'navstat_4.0_t-1',\n",
      "       'navstat_14.0_t-1', 'navstat_11.0_t-1', 'navstat_12.0_t-1',\n",
      "       'navstat_6.0_t-1', 'navstat_7.0_t-1', 'navstat_13.0_t-1',\n",
      "       'navstat_9.0_t-1', 'cog_t', 'sog_t', 'rot_t', 'heading_t', 'latitude_t',\n",
      "       'longitude_t', 'etaParsed_t', 'portLongitude_t', 'portLatitude_t',\n",
      "       'navstat_5.0_t', 'navstat_1.0_t', 'navstat_8.0_t', 'navstat_2.0_t',\n",
      "       'navstat_3.0_t', 'navstat_15.0_t', 'navstat_4.0_t', 'navstat_14.0_t',\n",
      "       'navstat_11.0_t', 'navstat_12.0_t', 'navstat_6.0_t', 'navstat_7.0_t',\n",
      "       'navstat_13.0_t', 'navstat_9.0_t', 'latitude_t+1', 'longitude_t+1',\n",
      "       'latitude_t+2', 'longitude_t+2'],\n",
      "      dtype='object')\n",
      "(1956134, 96)\n"
     ]
    }
   ],
   "source": [
    "print(supervised_h.columns)\n",
    "\n",
    "print(supervised_h.shape)\n",
    "\n",
    "def train_test_split(df, perc1, perc2, output_window):\n",
    "    y_list = []\n",
    "    for j in range(output_window):\n",
    "        y_list.append(f\"{\"longitude\"}_t+{j+1}\")\n",
    "        y_list.append(f\"{\"latitude\"}_t+{j+1}\")\n",
    "    ys = df[y_list]\n",
    "    Xs = df.drop(columns = y_list)\n",
    "\n",
    "    X_train = Xs.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    y_train = ys.iloc[:int(np.round(Xs.shape[0]*perc1)),:]\n",
    "    X_val = Xs.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    y_val = ys.iloc[int(np.round(Xs.shape[0]*perc1)):int(np.round(Xs.shape[0]*perc2)),:]\n",
    "    X_test = Xs.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "    y_test = ys.iloc[int(np.round(Xs.shape[0]*perc2)):,:]\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split(supervised_h, 0.75, 0.85, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X_train[\"navstat_7.0_t-3\"].iloc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = xgb.XGBRFRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.8465450034427957\n",
      "MSE: longitude_t+1    21.327158\n",
      "latitude_t+1      1.989872\n",
      "longitude_t+2    38.661797\n",
      "latitude_t+2      3.836467\n",
      "dtype: float64\n",
      "R2 Score: 0.9958446838366094\n",
      "RMSE: longitude_t+1    4.618134\n",
      "latitude_t+1     1.410628\n",
      "longitude_t+2    6.217861\n",
      "latitude_t+2     1.958690\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "results = {\n",
    "    \"MAE\": mean_absolute_error(y_val, preds),\n",
    "    \"MSE\": np.square(np.subtract(y_val,preds)).mean(),\n",
    "    \"R2 Score\": r2_score(y_val, preds),\n",
    "    \"RMSE\": np.sqrt(np.square(np.subtract(y_val,preds)).mean())\n",
    "}\n",
    "\n",
    "for metric, value in results.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
